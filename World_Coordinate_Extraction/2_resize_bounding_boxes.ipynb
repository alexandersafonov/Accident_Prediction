{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2_resize_bounding_boxes.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"code","metadata":{"id":"jG-B7_NKbwmP","colab_type":"code","outputId":"efb91b22-8b93-4c84-a760-0941a2dc46aa","executionInfo":{"status":"ok","timestamp":1579818778616,"user_tz":480,"elapsed":70916,"user":{"displayName":"ALEXANDER SAFONOV","photoUrl":"","userId":"06108573154481941124"}},"colab":{"base_uri":"https://localhost:8080/","height":670}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","%cd /content/gdrive/My\\ Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild\n","from image_utils import *\n","\n","%cd /content/gdrive/My\\ Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research\n","#%cd /content/gdrive/My\\ Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/\n","import sys\n","\n","!pip install tensorflow-graphics\n","\n","path_to_utils = '/content/gdrive/My Drive/Accident_Anticipation/EXTRACT_PHYSICS_NOTEBOOKS/utils'\n","sys.path.append(path_to_utils)\n","from distance_map_processing_utils import bounding_box_conversion, retrieve_distance_dir, binary_rectangle, retrieve_distance_dir\n","from distance_map_processing_utils import retrieve_frame_dir1, obtain_keys, obtain_keys1, h, sort_dir, find_bb_conv, conv_bb_based_off_existing_crop\n","\n","from __future__ import absolute_import, division, print_function\n","\n","from absl import logging\n","import os\n","import cv2\n","import re\n","import time\n","import glob\n","from matplotlib import pyplot as plt\n","\n","import numpy as np\n","from PIL import Image\n","\n","import tensorflow as tf\n","from depth_from_video_in_the_wild import model\n","from scipy import stats\n","\n","train_num = 126\n","test_num = 46\n","\n","## import function\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research\n","Requirement already satisfied: tensorflow-graphics in /usr/local/lib/python3.6/dist-packages (1.0.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-graphics) (1.4.1)\n","Requirement already satisfied: tensorflow>=1.13.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-graphics) (1.15.0)\n","Requirement already satisfied: absl-py>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-graphics) (0.9.0)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow-graphics) (1.17.5)\n","Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-graphics) (1.12.0)\n","Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.13.1->tensorflow-graphics) (0.2.2)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.13.1->tensorflow-graphics) (0.33.6)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.13.1->tensorflow-graphics) (3.1.0)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.13.1->tensorflow-graphics) (0.1.8)\n","Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.13.1->tensorflow-graphics) (1.15.1)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.13.1->tensorflow-graphics) (1.1.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.13.1->tensorflow-graphics) (1.15.0)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.13.1->tensorflow-graphics) (1.0.8)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.13.1->tensorflow-graphics) (1.11.2)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.13.1->tensorflow-graphics) (1.1.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.13.1->tensorflow-graphics) (3.10.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.13.1->tensorflow-graphics) (0.8.1)\n","Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.13.1->tensorflow-graphics) (1.15.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow>=1.13.1->tensorflow-graphics) (2.8.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow>=1.13.1->tensorflow-graphics) (42.0.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow>=1.13.1->tensorflow-graphics) (0.16.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow>=1.13.1->tensorflow-graphics) (3.1.1)\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Warning: To use the exr data format, please install the OpenEXR package following the instructions detailed in the README at github.com/tensorflow/graphics.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"x36-SY-uluAp","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"yIeTf-45hRsc","colab_type":"code","colab":{}},"source":["def shift_indices(batch_det_new):\n","  for batch in range(10):\n","    cur_batch = batch_det_new[batch, :, :, -1]\n","    cur_batch = cur_batch[cur_batch != 0]\n","    try:\n","      lowest_val = np.min(cur_batch)\n","    except:\n","      lowest_val = 1\n","    cur_batch[cur_batch != 0] = cur_batch[cur_batch != 0] + 1 - lowest_val\n","    batch_det_new[batch, :, :, -1][batch_det_new[batch, :, :, -1] != 0] = cur_batch\n","    unique_vals = np.unique(batch_det_new[batch, :, :, -1])\n","\n","    # print(unique_vals)\n","    consecutive_vals = np.arange(len(unique_vals))\n","\n","    for k in range(len(unique_vals)):\n","      if unique_vals[k] == 0:\n","        pass\n","      else:\n","        unique_inds = (np.argwhere(batch_det_new[batch, :, :, -1] == unique_vals[k]))\n","        batch_det_new[batch, unique_inds[:,0],unique_inds[:,1], -1] = consecutive_vals[k]\n","  return batch_det_new\n","\n","\n","\n","# training_path = '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/features/training-sort/output_sort11AGE=3IOU=0.15/'\n","# testing_path = '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/features/testing-sort/output_sort12AGE=3IOU=0.15/'\n","optimal_crop_path = '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det/'\n","save_path = '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_SORT_det/'\n","\n","training_path = '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/features/training-sort/output_sort9AGE=2IOU=0.3/'\n","testing_path = '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/features/testing-sort/output_sort10AGE=2IOU=0.3/'\n","\n","# ../../Anticipating-Accidents/dataset/features/testing-sort/output_sort10AGE=2IOU=0.3/\n","# ../../Anticipating-Accidents/dataset/features/training-sort/output_sort9AGE=2IOU=0.3/\n","\n","fixed_track_ids = (training_path, testing_path)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZSs8hQ_tFb1Z","colab_type":"text"},"source":["Create det file to point to optimal crops (run 2_processing_final_outputs.ipynb after)."]},{"cell_type":"code","metadata":{"id":"S3o8oCo5utRT","colab_type":"code","outputId":"26794333-5f6f-4d92-d842-dd9afffca824","executionInfo":{"status":"ok","timestamp":1579819098729,"user_tz":480,"elapsed":378770,"user":{"displayName":"ALEXANDER SAFONOV","photoUrl":"","userId":"06108573154481941124"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["## take random det file, test bounding box transformation on image\n","## load det, corresponding files\n","%matplotlib inline\n","import numpy as np\n","import time\n","import sys\n","from matplotlib import pyplot as plt\n","from matplotlib import patches\n","\n","str_modes = ['training','testing']\n","train_num = 126\n","test_num = 46\n","n_batch = [train_num, test_num ]\n","\n","ab = 0\n","feat_type = 'optimal_crops_det_2'\n","crop_type = 'optimal_crops_det'  #!!!\n","root_paths = (training_path, testing_path)\n","\n","for ab in range(2):\n","    ## Cloud root path:\n","    # root_path0 = '/home/safon007/share/datasets/Accident_Dataset'\n","    root_path0 = '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents'\n","    # for ab in range(len(str_modes)):\n","    str_mode = str_modes[ab]\n","    \n","    frame_path = root_path0+'/dataset/videos/frames/'\n","    feat_save_path = root_path0+'/preprocessed_features/'+feat_type+'/'+str_mode+'/'\n","    crop_pointer_path = root_path0+'/preprocessed_features/'+crop_type+'/'+str_mode+'/'\n","    # track_id_path = fixed_track_ids[ab]\n","    # root_path = root_path0+'/dataset/features/' +str_mode + '/'\n","    root_path = root_paths[ab]\n","\n","    ## Access given batches\n","    ## Augment/Amend the feature maps with bounding box, distance, optical flow and odometry\n","    root_num = len(os.listdir(root_path)) \n","    n_batchs = np.arange(1,root_num+1)\n","\n","    tStart_epoch = time.time()\n","    root_batch_list = os.listdir(root_path) \n","    count_batch = 1\n","    feat_in_root = sort_dir(root_batch_list)\n","    try:\n","        feat_in_save = sort_dir(os.listdir(feat_save_path))\n","\n","    except:\n","        \"Empty features folder!\"\n","        feat_in_save = []\n","\n","    missing_batches = np.setdiff1d(feat_in_root,feat_in_save)\n","\n","    if True:\n","    # if len(missing_batches) != 0:\n","        for batch in feat_in_root:\n","            # for batch in missing_batches:\n","              time_1 = time.time()\n","              print('Batch: ' + str(count_batch) + ' :: ' + batch)\n","              #curr_feature = root_batch_list[batch]\n","              curr_feature = batch\n","              all_data = np.load(root_path+curr_feature, allow_pickle = True) # initializing the current batch\n","              # [1]: First try: Adding bounding box locations to the feature map\n","              # data = all_data['data']\n","              labels = all_data['labels']\n","              # det = all_data['det']\n","              # det = all_data['new_det']\n","              det = all_data['sortdet']\n","              ID = all_data['ID']\n","              frame_paths, frame_labels = retrieve_dir1(labels, ID,str_mode, n_batch[ab])\n","              pointer_det = shift_indices(np.load(crop_pointer_path+curr_feature)['new_det'])\n","              new_det = conv_bb_based_off_existing_crop(det, pointer_det, frame_paths)\n","              args_output = feat_save_path+batch   \n","              # /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_SORT_det/training/batch_001.npz\n","\n","              #!! UNCOMMENT LINE BELOW::\n","              np.savez(args_output , new_det=new_det)\n","              print(args_output)\n","              print(time.time() - time_1)      \n","              # except:\n","              #     print(\"No depth map found for: \" + feat_save_path+batch)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Batch: 1 :: batch_001.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_001.npz\n","0.7603573799133301\n","Batch: 1 :: batch_002.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_002.npz\n","0.7330875396728516\n","Batch: 1 :: batch_003.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_003.npz\n","0.759876012802124\n","Batch: 1 :: batch_004.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_004.npz\n","0.7030735015869141\n","Batch: 1 :: batch_005.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_005.npz\n","0.6783947944641113\n","Batch: 1 :: batch_006.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_006.npz\n","0.697829008102417\n","Batch: 1 :: batch_007.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_007.npz\n","0.6828646659851074\n","Batch: 1 :: batch_008.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_008.npz\n","0.6766235828399658\n","Batch: 1 :: batch_009.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_009.npz\n","0.8226280212402344\n","Batch: 1 :: batch_010.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_010.npz\n","0.7397146224975586\n","Batch: 1 :: batch_011.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_011.npz\n","0.7395589351654053\n","Batch: 1 :: batch_012.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_012.npz\n","0.6296417713165283\n","Batch: 1 :: batch_013.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_013.npz\n","0.7275271415710449\n","Batch: 1 :: batch_014.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_014.npz\n","0.7955739498138428\n","Batch: 1 :: batch_015.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_015.npz\n","0.9952659606933594\n","Batch: 1 :: batch_016.npz\n","(720, 960, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/negative/000196/\n","(540, 1280, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/positive/000064/\n","(720, 960, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/negative/000114/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_016.npz\n","0.7269554138183594\n","Batch: 1 :: batch_017.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_017.npz\n","0.5923266410827637\n","Batch: 1 :: batch_018.npz\n","(720, 960, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/negative/000137/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_018.npz\n","0.6433720588684082\n","Batch: 1 :: batch_019.npz\n","(720, 960, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/negative/000185/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_019.npz\n","0.723604679107666\n","Batch: 1 :: batch_020.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_020.npz\n","0.955894947052002\n","Batch: 1 :: batch_021.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_021.npz\n","0.7304937839508057\n","Batch: 1 :: batch_022.npz\n","(540, 1280, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/negative/000128/\n","(720, 960, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/positive/000091/\n","(720, 960, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/negative/000138/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_022.npz\n","0.7865400314331055\n","Batch: 1 :: batch_023.npz\n","(720, 960, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/negative/000184/\n","(720, 960, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/positive/000067/\n","(720, 960, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/negative/000113/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_023.npz\n","0.558743953704834\n","Batch: 1 :: batch_024.npz\n","(540, 1280, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/negative/000129/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_024.npz\n","0.6979782581329346\n","Batch: 1 :: batch_025.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_025.npz\n","0.7650482654571533\n","Batch: 1 :: batch_026.npz\n","(540, 1280, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/negative/000127/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_026.npz\n","0.737189769744873\n","Batch: 1 :: batch_027.npz\n","(720, 960, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/negative/000186/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_027.npz\n","0.664391279220581\n","Batch: 1 :: batch_028.npz\n","(720, 960, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/negative/000136/\n","(720, 960, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/positive/000096/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_028.npz\n","0.756234884262085\n","Batch: 1 :: batch_029.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_029.npz\n","0.7193894386291504\n","Batch: 1 :: batch_030.npz\n","(720, 960, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/positive/000058/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_030.npz\n","0.7084920406341553\n","Batch: 1 :: batch_031.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_031.npz\n","0.7636137008666992\n","Batch: 1 :: batch_032.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_032.npz\n","0.6851222515106201\n","Batch: 1 :: batch_033.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_033.npz\n","0.6076681613922119\n","Batch: 1 :: batch_034.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_034.npz\n","0.6240279674530029\n","Batch: 1 :: batch_035.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_035.npz\n","0.7145473957061768\n","Batch: 1 :: batch_036.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_036.npz\n","0.6434087753295898\n","Batch: 1 :: batch_037.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_037.npz\n","0.6444797515869141\n","Batch: 1 :: batch_038.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_038.npz\n","0.7170345783233643\n","Batch: 1 :: batch_039.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_039.npz\n","0.6146495342254639\n","Batch: 1 :: batch_040.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_040.npz\n","0.7217204570770264\n","Batch: 1 :: batch_041.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_041.npz\n","0.732410192489624\n","Batch: 1 :: batch_042.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_042.npz\n","0.6999332904815674\n","Batch: 1 :: batch_043.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_043.npz\n","0.7031104564666748\n","Batch: 1 :: batch_044.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_044.npz\n","0.622370719909668\n","Batch: 1 :: batch_045.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_045.npz\n","0.7978818416595459\n","Batch: 1 :: batch_046.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_046.npz\n","0.8231277465820312\n","Batch: 1 :: batch_047.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_047.npz\n","0.7013001441955566\n","Batch: 1 :: batch_048.npz\n","(720, 960, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/negative/000360/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_048.npz\n","0.6884331703186035\n","Batch: 1 :: batch_049.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_049.npz\n","0.7693686485290527\n","Batch: 1 :: batch_050.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_050.npz\n","0.715782880783081\n","Batch: 1 :: batch_051.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_051.npz\n","0.7530608177185059\n","Batch: 1 :: batch_052.npz\n","(720, 960, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/negative/000359/\n","(720, 960, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/negative/000362/\n","(720, 960, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/positive/000166/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_052.npz\n","0.7836694717407227\n","Batch: 1 :: batch_053.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_053.npz\n","0.7194609642028809\n","Batch: 1 :: batch_054.npz\n","(720, 1274, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/negative/000393/\n","(720, 1274, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/negative/000385/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_054.npz\n","0.8379185199737549\n","Batch: 1 :: batch_055.npz\n","(720, 960, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/negative/000306/\n","(720, 960, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/negative/000324/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_055.npz\n","0.6996281147003174\n","Batch: 1 :: batch_056.npz\n","(720, 1274, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/negative/000395/\n","(720, 960, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/positive/000184/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_056.npz\n","0.7124261856079102\n","Batch: 1 :: batch_057.npz\n","(720, 960, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/negative/000358/\n","(720, 960, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/positive/000154/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_057.npz\n","0.6426951885223389\n","Batch: 1 :: batch_058.npz\n","(720, 960, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/positive/000192/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_058.npz\n","0.6553852558135986\n","Batch: 1 :: batch_059.npz\n","(720, 960, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/positive/000191/\n","(720, 960, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/negative/000305/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_059.npz\n","0.6900403499603271\n","Batch: 1 :: batch_060.npz\n","(720, 1274, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/negative/000394/\n","(720, 960, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/negative/000361/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_060.npz\n","0.6559555530548096\n","Batch: 1 :: batch_061.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_061.npz\n","1.0584635734558105\n","Batch: 1 :: batch_062.npz\n","(720, 962, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/negative/000466/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_062.npz\n","0.6507377624511719\n","Batch: 1 :: batch_063.npz\n","(720, 1274, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/positive/000212/\n","(720, 960, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/negative/000435/\n","(720, 960, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/positive/000235/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_063.npz\n","0.7319028377532959\n","Batch: 1 :: batch_064.npz\n","(720, 960, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/positive/000231/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_064.npz\n","0.7557032108306885\n","Batch: 1 :: batch_065.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_065.npz\n","0.7513151168823242\n","Batch: 1 :: batch_066.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_066.npz\n","0.7358410358428955\n","Batch: 1 :: batch_067.npz\n","(720, 960, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/negative/000434/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_067.npz\n","0.6603057384490967\n","Batch: 1 :: batch_068.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_068.npz\n","0.6912052631378174\n","Batch: 1 :: batch_069.npz\n","(720, 960, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/negative/000450/\n","(720, 1274, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/positive/000205/\n","(720, 962, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/negative/000465/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_069.npz\n","0.741513729095459\n","Batch: 1 :: batch_070.npz\n","(720, 960, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/negative/000451/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_070.npz\n","0.701446533203125\n","Batch: 1 :: batch_071.npz\n","(720, 960, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/negative/000433/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_071.npz\n","0.5874824523925781\n","Batch: 1 :: batch_072.npz\n","(720, 960, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/positive/000234/\n","(720, 960, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/positive/000243/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_072.npz\n","1.0760219097137451\n","Batch: 1 :: batch_073.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_073.npz\n","0.6031873226165771\n","Batch: 1 :: batch_074.npz\n","(720, 960, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/negative/000452/\n","(720, 962, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/negative/000467/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_074.npz\n","0.5937902927398682\n","Batch: 1 :: batch_075.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_075.npz\n","0.5691831111907959\n","Batch: 1 :: batch_076.npz\n","(720, 1270, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/positive/000300/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_076.npz\n","0.7576427459716797\n","Batch: 1 :: batch_077.npz\n","(718, 1280, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/positive/000266/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_077.npz\n","0.7666010856628418\n","Batch: 1 :: batch_078.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_078.npz\n","0.5850131511688232\n","Batch: 1 :: batch_079.npz\n","(720, 962, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/positive/000253/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_079.npz\n","0.5763766765594482\n","Batch: 1 :: batch_080.npz\n","(720, 960, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/negative/000591/\n","(720, 960, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/positive/000292/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_080.npz\n","0.6102128028869629\n","Batch: 1 :: batch_081.npz\n","(720, 1274, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/positive/000301/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_081.npz\n","0.6955149173736572\n","Batch: 1 :: batch_082.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_082.npz\n","0.6797492504119873\n","Batch: 1 :: batch_083.npz\n","(720, 1270, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/negative/000557/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_083.npz\n","0.6127123832702637\n","Batch: 1 :: batch_084.npz\n","(720, 1274, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/negative/000559/\n","(720, 1270, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/negative/000556/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_084.npz\n","0.6680834293365479\n","Batch: 1 :: batch_085.npz\n","(720, 1274, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/negative/000560/\n","(720, 960, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/negative/000590/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_085.npz\n","0.7213809490203857\n","Batch: 1 :: batch_086.npz\n","(720, 960, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/negative/000507/\n","(720, 960, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/negative/000589/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_086.npz\n","0.6493678092956543\n","Batch: 1 :: batch_087.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_087.npz\n","0.6177380084991455\n","Batch: 1 :: batch_088.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_088.npz\n","0.7465741634368896\n","Batch: 1 :: batch_089.npz\n","(720, 1270, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/negative/000558/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_089.npz\n","0.6847338676452637\n","Batch: 1 :: batch_090.npz\n","(720, 960, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/positive/000276/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_090.npz\n","0.6941249370574951\n","Batch: 1 :: batch_091.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_091.npz\n","1.0751805305480957\n","Batch: 1 :: batch_092.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_092.npz\n","1.0530438423156738\n","Batch: 1 :: batch_093.npz\n","(720, 960, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/positive/000315/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_093.npz\n","0.6374061107635498\n","Batch: 1 :: batch_094.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_094.npz\n","0.6710958480834961\n","Batch: 1 :: batch_095.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_095.npz\n","0.7931318283081055\n","Batch: 1 :: batch_096.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_096.npz\n","0.7388510704040527\n","Batch: 1 :: batch_097.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_097.npz\n","0.660703182220459\n","Batch: 1 :: batch_098.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_098.npz\n","0.7648305892944336\n","Batch: 1 :: batch_099.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_099.npz\n","0.6530332565307617\n","Batch: 1 :: batch_100.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_100.npz\n","0.727109432220459\n","Batch: 1 :: batch_101.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_101.npz\n","0.6485714912414551\n","Batch: 1 :: batch_102.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_102.npz\n","0.8215663433074951\n","Batch: 1 :: batch_103.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_103.npz\n","0.7423129081726074\n","Batch: 1 :: batch_104.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_104.npz\n","0.6531472206115723\n","Batch: 1 :: batch_105.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_105.npz\n","0.64404296875\n","Batch: 1 :: batch_106.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_106.npz\n","0.6964058876037598\n","Batch: 1 :: batch_107.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_107.npz\n","0.8684909343719482\n","Batch: 1 :: batch_108.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_108.npz\n","0.6876819133758545\n","Batch: 1 :: batch_109.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_109.npz\n","0.7203302383422852\n","Batch: 1 :: batch_110.npz\n","(720, 1274, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/negative/000794/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_110.npz\n","0.6997947692871094\n","Batch: 1 :: batch_111.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_111.npz\n","0.7925167083740234\n","Batch: 1 :: batch_112.npz\n","(720, 1252, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/negative/000749/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_112.npz\n","0.9559183120727539\n","Batch: 1 :: batch_113.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_113.npz\n","0.7208991050720215\n","Batch: 1 :: batch_114.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_114.npz\n","0.7145881652832031\n","Batch: 1 :: batch_115.npz\n","(720, 1274, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/negative/000796/\n","(720, 1252, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/negative/000751/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_115.npz\n","0.6738653182983398\n","Batch: 1 :: batch_116.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_116.npz\n","0.7066402435302734\n","Batch: 1 :: batch_117.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_117.npz\n","0.6861588954925537\n","Batch: 1 :: batch_118.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_118.npz\n","0.7180891036987305\n","Batch: 1 :: batch_119.npz\n","(720, 1274, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/negative/000795/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_119.npz\n","0.7215194702148438\n","Batch: 1 :: batch_120.npz\n","(720, 1252, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/training/negative/000750/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_120.npz\n","0.7459142208099365\n","Batch: 1 :: batch_121.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_121.npz\n","0.643315315246582\n","Batch: 1 :: batch_122.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_122.npz\n","0.66733717918396\n","Batch: 1 :: batch_123.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_123.npz\n","0.6708953380584717\n","Batch: 1 :: batch_124.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_124.npz\n","0.642326831817627\n","Batch: 1 :: batch_125.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_125.npz\n","0.647789478302002\n","Batch: 1 :: batch_126.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_126.npz\n","0.6327691078186035\n","Batch: 1 :: batch_127.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_127.npz\n","0.6745879650115967\n","Batch: 1 :: batch_128.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/training/batch_128.npz\n","0.6673028469085693\n","Batch: 1 :: batch_001.npz\n","(720, 1274, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/negative/000884/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/testing/batch_001.npz\n","0.6075561046600342\n","Batch: 1 :: batch_002.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/testing/batch_002.npz\n","0.7758324146270752\n","Batch: 1 :: batch_003.npz\n","(720, 1274, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/negative/000883/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/testing/batch_003.npz\n","1.1886498928070068\n","Batch: 1 :: batch_004.npz\n","(720, 1270, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000501/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/testing/batch_004.npz\n","0.6558394432067871\n","Batch: 1 :: batch_005.npz\n","(720, 1270, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/negative/000913/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/testing/batch_005.npz\n","0.677983283996582\n","Batch: 1 :: batch_006.npz\n","(720, 1274, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/negative/000882/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/testing/batch_006.npz\n","0.6270589828491211\n","Batch: 1 :: batch_007.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/testing/batch_007.npz\n","0.6554429531097412\n","Batch: 1 :: batch_008.npz\n","(720, 1274, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000484/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/testing/batch_008.npz\n","1.8818550109863281\n","Batch: 1 :: batch_009.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/testing/batch_009.npz\n","3.806372880935669\n","Batch: 1 :: batch_010.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/testing/batch_010.npz\n","5.925468683242798\n","Batch: 1 :: batch_011.npz\n","(720, 1270, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/negative/000911/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/testing/batch_011.npz\n","6.419831991195679\n","Batch: 1 :: batch_012.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/testing/batch_012.npz\n","5.248374938964844\n","Batch: 1 :: batch_013.npz\n","(720, 1270, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/negative/000912/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/testing/batch_013.npz\n","5.46467137336731\n","Batch: 1 :: batch_014.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/testing/batch_014.npz\n","5.420983552932739\n","Batch: 1 :: batch_015.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/testing/batch_015.npz\n","6.886678695678711\n","Batch: 1 :: batch_016.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/testing/batch_016.npz\n","4.73050594329834\n","Batch: 1 :: batch_017.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/testing/batch_017.npz\n","6.24708104133606\n","Batch: 1 :: batch_018.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/testing/batch_018.npz\n","6.799580812454224\n","Batch: 1 :: batch_019.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/testing/batch_019.npz\n","4.695710897445679\n","Batch: 1 :: batch_020.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/testing/batch_020.npz\n","6.104854106903076\n","Batch: 1 :: batch_021.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/testing/batch_021.npz\n","6.721641302108765\n","Batch: 1 :: batch_022.npz\n","(720, 1270, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000544/\n","(720, 1270, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/negative/000982/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/testing/batch_022.npz\n","6.097591400146484\n","Batch: 1 :: batch_023.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/testing/batch_023.npz\n","5.150785207748413\n","Batch: 1 :: batch_024.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/testing/batch_024.npz\n","4.778439044952393\n","Batch: 1 :: batch_025.npz\n","(720, 960, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/negative/001010/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/testing/batch_025.npz\n","7.474796772003174\n","Batch: 1 :: batch_026.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/testing/batch_026.npz\n","7.236391544342041\n","Batch: 1 :: batch_027.npz\n","(720, 960, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/negative/001012/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/testing/batch_027.npz\n","6.5371010303497314\n","Batch: 1 :: batch_028.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/testing/batch_028.npz\n","6.68629002571106\n","Batch: 1 :: batch_029.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/testing/batch_029.npz\n","5.505577325820923\n","Batch: 1 :: batch_030.npz\n","(720, 960, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/negative/001011/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/testing/batch_030.npz\n","5.7949912548065186\n","Batch: 1 :: batch_031.npz\n","(718, 1280, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/negative/001118/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/testing/batch_031.npz\n","5.345009088516235\n","Batch: 1 :: batch_032.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/testing/batch_032.npz\n","5.833278179168701\n","Batch: 1 :: batch_033.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/testing/batch_033.npz\n","5.346201658248901\n","Batch: 1 :: batch_034.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/testing/batch_034.npz\n","5.798564672470093\n","Batch: 1 :: batch_035.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/testing/batch_035.npz\n","4.939507007598877\n","Batch: 1 :: batch_036.npz\n","(720, 958, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000579/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/testing/batch_036.npz\n","5.369190216064453\n","Batch: 1 :: batch_037.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/testing/batch_037.npz\n","6.3482842445373535\n","Batch: 1 :: batch_038.npz\n","(718, 1280, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/negative/001117/\n","(676, 1280, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000606/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/testing/batch_038.npz\n","7.117258310317993\n","Batch: 1 :: batch_039.npz\n","(540, 1280, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000595/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/testing/batch_039.npz\n","5.479170799255371\n","Batch: 1 :: batch_040.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/testing/batch_040.npz\n","6.861534833908081\n","Batch: 1 :: batch_041.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/testing/batch_041.npz\n","6.45623517036438\n","Batch: 1 :: batch_042.npz\n","(718, 1280, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/negative/001119/\n","(676, 1280, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/negative/001102/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/testing/batch_042.npz\n","5.348056793212891\n","Batch: 1 :: batch_043.npz\n","(720, 960, 3) /content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000558/\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/testing/batch_043.npz\n","5.85847020149231\n","Batch: 1 :: batch_044.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/testing/batch_044.npz\n","4.459745645523071\n","Batch: 1 :: batch_045.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/testing/batch_045.npz\n","6.288040399551392\n","Batch: 1 :: batch_046.npz\n","/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/testing/batch_046.npz\n","4.553101301193237\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CY5sgOWJ29Wq","colab_type":"code","outputId":"112495bd-49ff-491a-8ead-53f511a3a910","executionInfo":{"status":"ok","timestamp":1579673298314,"user_tz":480,"elapsed":414,"user":{"displayName":"ALEXANDER SAFONOV","photoUrl":"","userId":"06108573154481941124"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["print(glob.glob(frame_paths[1]+'/*.jpg'))\n","x = np.clip(np.asarray(Image.open( img ), dtype=float) / 255, 0, 1)\n","\n","\n","# print(os.listdir(frame_paths[1]))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame93.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame4.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame94.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame40.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame11.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame2.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame86.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame52.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame48.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame68.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame67.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame76.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame38.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame53.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame0.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame81.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame63.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame1.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame62.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame15.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame17.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame74.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame3.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame29.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame37.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame9.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame65.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame25.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame44.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame87.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame54.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame83.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame34.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame69.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame55.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame16.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame97.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame45.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame98.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame46.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame7.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame61.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame33.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame99.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame13.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame57.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame88.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame49.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame31.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame12.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame18.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame41.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame90.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame51.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame84.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame89.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame66.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame72.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame6.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame24.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame82.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame78.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame23.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame43.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame91.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame36.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame19.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame64.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame21.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame27.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame35.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame96.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame5.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame8.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame85.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame20.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame42.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame58.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame59.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame26.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame47.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame92.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame79.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame75.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame50.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame32.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame95.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame30.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame77.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame28.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame80.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame71.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame22.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame10.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame39.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame14.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame56.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame60.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame73.jpg', '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/testing/positive/000490/frame70.jpg']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vXFsacWSF50C","colab_type":"code","colab":{}},"source":["# Create dictionary that contains all corrected bounding boxes\n","# for each batc\n","\n","## Correctly crop images\n","#(1): Function retrieves the preferential crop\n","\n","#(2): Retrieve and save cropped images\n","\n","#(3): Create masks\n","\n","## Create depth maps"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kX6b9euVa7zu","colab_type":"code","outputId":"6de3e3db-fc99-4c6a-e4cb-2c27c44124f1","executionInfo":{"status":"error","timestamp":1579671791819,"user_tz":480,"elapsed":7078,"user":{"displayName":"ALEXANDER SAFONOV","photoUrl":"","userId":"06108573154481941124"}},"colab":{"base_uri":"https://localhost:8080/","height":229}},"source":["## take random det file, test bounding box transformation on image\n","## load det, corresponding files\n","%matplotlib inline\n","import numpy as np\n","import time\n","import sys\n","import os\n","from matplotlib import pyplot as plt\n","from matplotlib import patches\n","\n","str_modes = ['training','testing']\n","train_num = 126\n","test_num = 46\n","n_batch = [train_num, test_num ]\n","\n","ab = 0\n","feat_type = 'reformatted_det'\n","\n","for ab in range(2):\n","    ## Cloud root path:\n","    # root_path0 = '/home/safon007/share/datasets/Accident_Dataset'\n","    root_path0 = '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents'\n","    # for ab in range(len(str_modes)):\n","    str_mode = str_modes[ab]\n","    root_path = root_path0+'/dataset/features/' +str_mode + '/'\n","    frame_path = root_path0+'/dataset/videos/frames/'\n","    feat_save_path = root_path0+'/preprocessed_features/'+feat_type+'/'+str_mode+'/'\n","\n","    ## Access given batches\n","    ## Augment/Amend the feature maps with bounding box, distance, optical flow and odometry\n","    # root_num = len(os.listdir(root_path)) \n","    # n_batchs = np.arange(1,root_num+1)\n","\n","    tStart_epoch = time.time()\n","    root_batch_list = os.listdir(root_path) \n","    count_batch = 1\n","    feat_in_root = sort_dir(root_batch_list)\n","    try:\n","        feat_in_save = sort_dir(os.listdir(feat_save_path))\n","\n","    except:\n","        \"Empty features folder!\"\n","        feat_in_save = []\n","\n","    missing_batches = np.setdiff1d(feat_in_root,feat_in_save)\n","\n","#     if True:\n","    if len(missing_batches) != 0:\n","#         for batch in feat_in_root:\n","            for batch in missing_batches:\n","              print('Batch: ' + str(count_batch) + ' :: ' + batch)\n","              #curr_feature = root_batch_list[batch]\n","              curr_feature = batch\n","              all_data = np.load(root_path+curr_feature, allow_pickle = True) # initializing the current batch\n","              # [1]: First try: Adding bounding box locations to the feature map\n","              # data = all_data['data']\n","              labels = all_data['labels']\n","              det = all_data['det']\n","              ID = all_data['ID']\n","\n","              try:\n","                  dist_list = retrieve_distance_dir(labels, ID, str_mode, dist_dir, n_batch[ab])\n","                  shape_list = list()\n","                  for k in range(10):\n","                      shape_list.append(np.load(dist_list[k])['input_shape'])\n","\n","                  new_det = bounding_box_conversion(det, shape_list)\n","\n","                  args_output = feat_save_path+batch\n","\n","                  np.savez(args_output , new_det=new_det)\n","                  print(args_output)\n","                    \n","              except:\n","                  print(\"No depth map found for: \" + feat_save_path+batch)\n"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-272d915c67ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mroot_batch_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mcount_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mfeat_in_root\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msort_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_batch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mfeat_in_save\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msort_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat_save_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'sort_dir' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"MVajl8pAa7zy","colab_type":"text"},"source":["Get distance features"]},{"cell_type":"code","metadata":{"id":"73BvcMGKa7zz","colab_type":"code","colab":{}},"source":["## note that if we are able to calculate intrinsic camera parameters (pending release), \n","#  the google codes have a much better method for getting to global coordinates\n","def get_XZ(dis_imgs, det):\n","    output_array = np.zeros((len(dis_imgs),100,19))\n","    output_features = np.zeros((len(dis_imgs),100,19,2))\n","    \n","#     try:\n","    for ak1 in range(len(dis_imgs)): # retrieve distance matrices\n","        dis_vid = np.load(dis_imgs[ak1], allow_pickle=True)\n","\n","        for ak2 in range(100): # retrieve image/frame from video\n","\n","            crop_type = det[ak1,ak2,:,-2]\n","            if np.any(crop_type == 1):\n","                crop_str = 'distance_upper'\n","            elif np.any(crop_type == 3):\n","                crop_str = 'distance_lower'\n","            elif np.any(crop_type == 2):\n","                crop_str = 'distance_middle'\n","            else:\n","                crop_str = ''\n","\n","            if crop_str == '':\n","                pass\n","#                     print('Distance measurement missing!')\n","            else:\n","                if np.any(dis_vid[crop_str]) == None:\n","                    dis_vid1 = dis_vid['distance_middle']\n","                else:\n","                    dis_vid1 = dis_vid[crop_str] \n","                bound_boxes = det[ak1,ak2,:,:].astype(int) # retrieve current frame from the current video\n","                num_boxes = bound_boxes.shape[0]\n","                dis_frame = dis_vid1[ak2,:,:,0]\n","\n","                ak3_iter = 0\n","                for ak3 in range(19):\n","                    if np.sum(bound_boxes[ak3,:]) != 0:\n","                        c_v = np.floor(dis_frame.shape[1]/2)\n","    #                     print(bound_boxes)\n","                        u, v = np.floor((bound_boxes[ak3,1]+bound_boxes[ak3,3])/2), np.floor((bound_boxes[ak3,0]+bound_boxes[ak3,2])/2)\n","                        if u > 127:\n","                            u = 127\n","#                                     print(\"u out of bounds!!\")\n","                        if v > 415:\n","                            v = 415\n","#                                     print(\"v out of bounds!!\")\n","                        output_features[ak1,ak2,ak3, 1] = dis_frame[int(u), int(v)]\n","                        f_v = 60 ####!!! Setting horizontal focal length to 2.45 for all videos\n","                        output_features[ak1,ak2,ak3, 0] = (v-c_v)*(dis_frame[int(u),int(v)]/(f_v))\n","                        if output_features[ak1,ak2,ak3, 1] == 0:\n","                            print(dis_frame[int(u), int(v)])\n","                            print(dis_frame.shape)\n","                            print('Empty BB')\n","                            print(ak1,ak2,ak3, u, v)\n","                    ak3_iter += 1\n","#                 else:\n","#                     print('No distance metric')\n","#     except:\n","#         print('File not found!')\n","\n","    return output_features"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EvdXBeOaa7z2","colab_type":"code","colab":{}},"source":["## take random det file, test bounding box transformation on image\n","## load det, corresponding files\n","%matplotlib inline\n","import numpy as np\n","import time\n","import sys\n","from matplotlib import pyplot as plt\n","from matplotlib import patches\n","str_modes = ['training','testing']\n","\n","##\n","ab = 0\n","feat_type = '5_backprop_xz'\n","###\n","\n","\n","for ab in range(2):\n","    ## Cloud root path:\n","    root_path0 = '/home/safon007/share/datasets/Accident_Dataset'\n","\n","    # for ab in range(len(str_modes)):\n","    str_mode = str_modes[ab]\n","    root_path = root_path0+'/dataset/features/' +str_mode + '/'\n","    frame_path = root_path0+'/dataset/videos/frames/'\n","    feat_save_path = root_path0+'/preprocessed_features/'+feat_type+'/'+str_mode+'/'\n","    det_path = root_path0+'/preprocessed_features/reformatted_det'+'/'+str_mode+'/'\n","\n","    ## Access given batches\n","    ## Augment/Amend the feature maps with bounding box, distance, optical flow and odometry\n","    root_num = len(os.listdir(root_path)) \n","    n_batchs = np.arange(1,root_num+1)\n","\n","    tStart_epoch = time.time()\n","    root_batch_list = os.listdir(root_path) \n","    count_batch = 1\n","    feat_in_root = sort_dir(root_batch_list)\n","    try:\n","        feat_in_save = sort_dir(os.listdir(feat_save_path))\n","\n","    except:\n","        \"Empty features folder!\"\n","        feat_in_save = []\n","\n","    missing_batches = np.setdiff1d(feat_in_root,feat_in_save)\n","\n","#     if True:\n","    if len(missing_batches) != 0:\n","#         for batch in feat_in_root:\n","        for batch in missing_batches:\n","          print('Batch: ' + str(count_batch) + ' :: ' + batch)\n","          #curr_feature = root_batch_list[batch]\n","          curr_feature = batch\n","          all_data = np.load(root_path+curr_feature, allow_pickle = True) # initializing the current batch\n","          new_det_data = np.load(det_path+curr_feature, allow_pickle = True)\n","          # [1]: First try: Adding bounding box locations to the feature map\n","          data = all_data['data']\n","          labels = all_data['labels']\n","          det = new_det_data['new_det']\n","          ID = all_data['ID']\n","    \n","                \n","          dist_list = retrieve_distance_dir(labels, ID, str_mode, dist_dir, n_batch[ab])\n","          output_xz = get_XZ(dist_list, det)\n"," \n","#           new_det = bounding_box_conversion(det, shape_list)\n","        \n","          args_output = feat_save_path+batch\n","            \n","          np.savez(args_output , distance=output_xz)\n","          print('Batch saved!')\n","                "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sdZcfxH6a7z5","colab_type":"code","outputId":"f1d96ba0-0769-4ef4-cd8c-9914dadd7d62","colab":{}},"source":["print(outpdist_listut_xz.shape)\n","print(outpdist_listut_xz[5,:,1,0])\n","print(output_xz[7,:,1,1])\n","print(det[7,:,1,0:4])\n","print(dist_list[7])\n","cur_crop = np.load(dist_list[7])['distance_middle']"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(10, 100, 19, 2)\n","[-1.10289243  1.18782821  1.18655083  1.18917255  1.17234548  2.69802544\n","  2.58577579  2.53766643 -2.65496754 -2.62015508 -2.63814639 -2.69060757\n"," -2.30516479  0.98382385  0.97761762  0.97979963  0.92201033  0.90937757\n","  2.50957425  2.5482783   0.83064809 -1.53386658 -1.54682609  0.74847715\n","  0.70258828  0.64732619  2.4414525   0.60466869  2.42529595 -2.310935\n","  2.37238637 -0.60258449  0.48996127 -2.36669993 -3.24740582 -0.99086419\n"," -2.15618286 -1.32430949 -2.9570538   2.0117434  -2.9869159  -2.9979518\n"," -0.13408759 -1.90745582  1.89736678  1.48707212  0.12456959 -3.04137963\n","  1.76088334  1.80448748 -2.85363142 -0.01997939  2.02625121 -0.0581193\n"," -3.11456808 -3.05697895  1.62668187 -2.61140178 -0.30737255 -0.32162879\n","  1.80483067 -0.36509562 -2.11646354 -2.94144422 -3.07615232 -2.12058582\n"," -1.69599279 -3.13140421 -3.23503479 -1.51588368 -1.43214172 -2.98315371\n"," -3.20527836 -3.04098071  0.61646186 -3.11487451  1.03776049 -1.87351656\n"," -2.9626934  -3.21513216 -3.04574001 -2.98537165 -3.12524042 -3.10822706\n"," -0.79263779 -3.10153833  0.96959482  0.89233093 -3.09576988 -3.08368464\n"," -3.08252735 -3.13828354 -1.46850757 -1.44665118 -1.42917556 -0.45732142\n"," -1.46644666 -1.50083194 -1.46919982 -1.48812255]\n","[1.36583817 0.63315445 0.64271939 0.67349195 0.69366276 0.71911377\n"," 0.70621169 0.67485756 0.73955381 0.71919262 0.75589031 0.78628963\n"," 0.74891651 1.3716445  0.70695364 0.77926683 0.8193242  0.82488281\n"," 0.79112715 0.84481066 0.84199077 0.82945263 0.85664755 0.75735879\n"," 0.73413062 0.8244341  0.82035673 0.83425009 0.84495592 0.82938397\n"," 0.83365297 0.85530609 0.73190373 0.74568844 0.76154327 0.74536395\n"," 0.7456882  0.         0.         0.         1.20526981 1.14420581\n"," 1.14128578 1.27067745 1.44108737 0.89828169 1.37723422 1.3073467\n"," 0.86836159 0.76005971 0.87237817 0.8946262  0.71341693 0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.9169656\n"," 0.         0.         0.94695252 0.         0.84800988 0.\n"," 1.1929704  0.         0.         0.         0.         0.84050429\n"," 0.78863305 0.8277967  0.         0.76902741 0.7701053  0.\n"," 0.         0.77439666 0.         0.80258799 0.89262265 0.81438017\n"," 0.81589466 0.81439328 0.82826042 0.82766479 0.83128923 0.86780012\n"," 0.86005104 0.90477586 0.89701647 0.9353255 ]\n","[[355.  57. 365.  89.]\n"," [248.  56. 254.  68.]\n"," [211.  58. 223.  71.]\n"," [214.  50. 230.  71.]\n"," [251.  57. 255.  70.]\n"," [285.  58. 294.  71.]\n"," [283.  57. 292.  70.]\n"," [182.  52. 195.  71.]\n"," [352.  53. 365.  87.]\n"," [251.  55. 255.  70.]\n"," [251.  54. 255.  70.]\n"," [157.  52. 168.  69.]\n"," [254.  55. 260.  68.]\n"," [250.  55. 255.  68.]\n"," [ 89.   0.  98.   0.]\n"," [254.  57. 260.  71.]\n"," [331.  56. 337.  75.]\n"," [113.  56. 123.  65.]\n"," [253.  58. 263.  71.]\n"," [102.  55. 112.  66.]\n"," [ 96.  55. 108.  67.]\n"," [ 87.  54. 100.  68.]\n"," [352.  53. 366.  90.]\n"," [ 80.  54.  93.  69.]\n"," [ 78.  55.  90.  70.]\n"," [350.  53. 368.  89.]\n"," [351.  52. 367.  90.]\n"," [330.  52. 338.  76.]\n"," [ 68.  63.  76.  74.]\n"," [220.  51. 236.  66.]\n"," [ 52.  55.  61.  69.]\n"," [ 13.  58.  19.  70.]\n"," [ 46.  57.  56.  69.]\n"," [233.  56. 242.  69.]\n"," [ 39.  57.  49.  70.]\n"," [ 38.  55.  46.  69.]\n"," [229.  53. 237.  65.]\n"," [ 29.  61.  34.  69.]\n"," [220.   0. 234.   0.]\n"," [ 29.  56.  38.  69.]\n"," [133.  50. 141.  71.]\n"," [228.  62. 236.  72.]\n"," [226.  62. 235.  73.]\n"," [ 20.  59.  27.  69.]\n"," [330.  52. 337.  75.]\n"," [ 17.  56.  22.  65.]\n"," [134.  49. 141.  69.]\n"," [199.  56. 205.  67.]\n"," [ 21.  56.  35.  76.]\n"," [219.  52. 239.  65.]\n"," [201.  57. 206.  66.]\n"," [211.  57. 220.  69.]\n"," [133.  48. 141.  70.]\n"," [330.  52. 337.  76.]\n"," [133.  47. 141.  70.]\n"," [331.  52. 337.  78.]\n"," [209.  56. 216.  68.]\n"," [135.  49. 141.  64.]\n"," [134.  48. 141.  66.]\n"," [134.  48. 141.  66.]\n"," [208.   0. 214.   0.]\n"," [134.  48. 142.  65.]\n"," [134.   0. 141.   0.]\n"," [134.  48. 141.  65.]\n"," [134.  49. 141.  64.]\n"," [202.  56. 209.  66.]\n"," [134.  48. 141.  64.]\n"," [134.  48. 141.  65.]\n"," [220.  51. 239.  65.]\n"," [201.  55. 207.  65.]\n"," [195.  57. 202.  67.]\n"," [221.  50. 239.  66.]\n"," [195.  57. 202.  66.]\n"," [194.   0. 199.   0.]\n"," [133.  48. 142.  68.]\n"," [221.   0. 227.   0.]\n"," [197.  57. 202.  66.]\n"," [331.  56. 337.  75.]\n"," [331.  57. 337.  75.]\n"," [219.   0. 235.   0.]\n"," [219.  53. 235.  64.]\n"," [134.  50. 143.  71.]\n"," [ 84.  54. 100.  64.]\n"," [134.  50. 143.  71.]\n"," [134.  50. 143.  70.]\n"," [134.  49. 143.  70.]\n"," [237.   0. 241.   0.]\n"," [346.  62. 352.  76.]\n"," [331.  52. 341.  75.]\n"," [237.   0. 243.   0.]\n"," [330.  52. 341.  76.]\n"," [133.  47. 141.  69.]\n"," [238.  56. 246.  66.]\n"," [238.  57. 248.  69.]\n"," [242.  56. 249.  67.]\n"," [196.  60. 201.  70.]\n"," [331.  56. 337.  74.]\n"," [195.  58. 201.  70.]\n"," [249.  55. 254.  65.]\n"," [251.  57. 256.  69.]]\n","/home/safon007/share/datasets/Accident_Dataset/preprocessed_features/depth_maps_1/testing/negative/001092.npz\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6RlXaEi5a7z8","colab_type":"code","colab":{}},"source":["plt.imshow(cur_crop[11,:,:,0])\n","print(cur_crop[11,24,51,0])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CIBTSIdwa7z_","colab_type":"code","colab":{}},"source":["print(det.shape)\n","7,:,1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BhOOQKNWa70V","colab_type":"code","colab":{}},"source":["# print(det_reshape.shape)\n","batch = 8\n","frame =20\n","agent = 1\n","\n","cur_frame = cv2.imread(image_list[batch]+sort_dir(os.listdir(image_list[batch]))[frame] )\n","\n","dist_map = np.load(dist_list[batch])\n","\n","file_list = dist_map.files\n","print(file_list)\n","shape_list = list()\n","for k in range(10):\n","    shape_list.append(np.load(dist_list[k])['input_shape'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3SD3_wMw6fWK","colab_type":"text"},"source":["Plotting Code"]},{"cell_type":"code","metadata":{"id":"qzJQBZUma70Z","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","from PIL import Image\n","import numpy as np\n","\n","img = cur_frame\n","\n","bboxes = det[batch]\n","new_bboxes = bboxes[frame]\n","new_bboxes = new_bboxes[~np.all(new_bboxes == 0, axis=1)] ## take out zero values from new_bboxes\n","\n","\n","img_path = image_list[batch]+sort_dir(os.listdir(image_list[batch]))[frame] \n","im = np.array(Image.open(img_path), dtype=np.uint8)\n","\n","# Create figure and axes\n","fig,ax = plt.subplots(1)\n","\n","# Display the image\n","ax.imshow(im)\n","for num_box in range(new_bboxes.shape[0]):\n","    det1 = det[batch, frame, num_box,:]\n","    x1, y1 ,x2,y2  = det1[0],det1[1],det1[2],det1[3]\n","#     x1, y1 ,x2,y2 = bb1[0], bb1[1], bb1[2], bb1[3]\n","    rect = patches.Rectangle((x1,y1),x2-x1,y2-y1,linewidth=1,edgecolor='r',facecolor='none')\n","    ax.add_patch(rect)\n","    print(det1)\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"GChTKHlXz0R1","colab":{}},"source":["output_base_root = '/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/depth_maps/720_1280_maps/'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BEqmSzYta70j","colab_type":"text"},"source":["# Extracting xz features"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"EAenEllQ0RPu"},"source":["Iterate Across batches, creating modified det files *and global xz coordinates"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"QIlzq3scysm-"},"source":["Previous code on extracting global coordinates"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9toOOEQyquiI","colab":{}},"source":["def load_images(image_files):\n","    from skimage.transform import resize\n","    loaded_images = []\n","    iter1 = 0\n","\n","    for file in image_files:\n","        crop_middle, crop_upper, crop_lower, img_shape = selective_cropping(file)\n","\n","        if iter1 == 0:\n","          img_stack_middle, img_stack_upper, img_stack_lower = crop_middle, crop_upper, crop_lower\n","        elif img_stack_upper.any() != None:\n","          img_stack_middle, img_stack_upper, img_stack_lower = np.concatenate((img_stack_middle, crop_middle), axis = 0), np.concatenate((img_stack_upper, crop_upper), axis = 0), np.concatenate((img_stack_lower, crop_lower), axis = 0),\n","        else:\n","          img_stack_middle = np.concatenate((img_stack_middle, crop_middle), axis = 0)\n","        iter1+=1\n","\n","\n","    return img_stack_middle, img_stack_upper, img_stack_lower, img_shape\n","\n","\n","def crop(img):\n","    # Perform center cropping, preserving 50% vertically.\n","    middle_perc = 0.50\n","    left = 1-middle_perc\n","    half = left/2\n","    a = img[int(img.shape[0]*(half)):int(img.shape[0]*(1-half)), :]\n","\n","    # Resize to match target height while preserving aspect ratio.\n","    wdt = int((128*a.shape[1]/a.shape[0]))\n","    x_scaling = float(wdt)/a.shape[1]\n","    y_scaling = 128.0/a.shape[0]\n","    b = cv2.resize(a, (wdt, 128))\n","\n","    # Perform center cropping horizontally.\n","    remain = b.shape[1] - 416\n","    # cx /= (b.shape[1]/416)\n","    c = b[:, int(remain/2):b.shape[1]-int(remain/2)]\n","\n","    return c\n","\n","def crop_upper(img):\n","    # cropping the top\n","    middle_perc = 0.50\n","    left = 1-middle_perc\n","    half = left/2\n","    a = img[0:int(img.shape[0]*(middle_perc)), :]\n","    wdt = int((128*a.shape[1]/a.shape[0]))\n","    x_scaling = float(wdt)/a.shape[1]\n","    y_scaling = 128.0/a.shape[0]\n","    b = cv2.resize(a, (wdt, 128))\n","    remain = b.shape[1] - 416\n","    c = b[:, int(remain/2):b.shape[1]-int(remain/2)]\n","    return c\n","\n","def crop_lower(img):\n","    # cropping the top\n","    middle_perc = 0.50\n","    left = 1-middle_perc\n","    half = left/2\n","    a = img[(-1)*int(img.shape[0]*(middle_perc))::, :]\n","    wdt = int((128*a.shape[1]/a.shape[0]))\n","    x_scaling = float(wdt)/a.shape[1]\n","    y_scaling = 128.0/a.shape[0]\n","    b = cv2.resize(a, (wdt, 128))\n","    remain = b.shape[1] - 416\n","    c = b[:, int(remain/2):b.shape[1]-int(remain/2)]\n","    return c\n","\n","# random functions\n","def obtain_keys(lis):\n","    key_ls = list()\n","    for k in lis:\n","        integer = re.split('([0-9]+)', k)[1]\n","        key_ls.append(int(integer))\n","    return(key_ls)\n","  \n","def obtain_keys1(lis):\n","    key_ls = list()\n","    for k in lis:\n","        integer = re.split('([0-9]+)', k)[3]\n","        key_ls.append(int(integer))\n","    return(key_ls)\n","  \n","def h(seq):\n","    return sorted(range(len(seq)), key=seq.__getitem__)\n","  \n","def sort_dir(lis):\n","    key_ls = h(obtain_keys(lis))\n","    return [lis[i] for i in key_ls]\n","\n","## Perform cropping and resizing, place into network\n","def selective_cropping(img):\n","  x = np.clip(np.asarray(Image.open( img ), dtype=float) / 255, 0, 1)\n","  cropped = np.expand_dims(crop(x), axis = 0)\n","  cropped1 = None\n","  cropped2 = None\n","  if (np.abs(cropped.shape[1]-128)>30) and (np.abs(cropped.shape[2]-416)>30):\n","    x_1 = np.zeros((720,1280, 3))\n","    x_1[0:x.shape[0], 0:x.shape[1], :] = x  \n","    cropped = np.expand_dims(crop(x_1), axis = 0)\n","    print(\"Cropping pattern did not fit, resized.\")\n","    print(img_folders)\n","  else:\n","    cropped1 = np.expand_dims(crop_upper(x), axis = 0)[:,:,0:-1,:]\n","    cropped2 = np.expand_dims(crop_lower(x), axis = 0)[:,:,0:-1,:]\n","  cropped = cropped[:,:,0:-1,:]\n","  img_shape = x.shape\n","  return cropped, cropped1, cropped2, img_shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zmeUUj8pqosg","colab":{}},"source":["tf.reset_default_graph() \n","train_model = model.Model(data_dir='depth_from_video_in_the_wild/data_example',is_training=True)\n","saver  = train_model.saver\n","\n","saver = tf.train.Saver()\n","sess = tf.Session()\n","saver.restore(sess, save_path = 'depth_from_video_in_the_wild/depth_cp_2/model-1000977')\n","\n","depth_model = model.Model(is_training=False, batch_size = 100)"],"execution_count":0,"outputs":[]}]}