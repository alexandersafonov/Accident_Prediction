{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"0_crop_images","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"SPYQqlY1cokE","colab_type":"code","outputId":"0a732128-3c2f-4b22-e2c0-b18a0d3059b5","executionInfo":{"status":"ok","timestamp":1580882933761,"user_tz":480,"elapsed":24497,"user":{"displayName":"ALEXANDER SAFONOV","photoUrl":"","userId":"06108573154481941124"}},"colab":{"base_uri":"https://localhost:8080/","height":154}},"source":["from absl import app, flags, logging\n","import numpy as np\n","import cv2\n","import os, glob, shutil, re\n","from matplotlib import pyplot as plt\n","from PIL import Image\n","import time\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","# import sys\n","# sys.path.append('/content/gdrive/My_Drive/Accident_Anticipation/depth_estimation/DenseDepth/google_distance_code/google_dist_code_1/google-research')\n","# %cd /content/gdrive/My\\ Drive/Accident_Anticipation/depth_estimation/DenseDepth/google_distance_code/google_dist_code_1/google-research\n","# %cd /content/gdrive/My\\ Drive/Accident_Anticipation/depth_estimation/google_distance_code/\n","# from image_utils import sort_dir, retrieve_dir1, h, obtain_keys1, load_images\n","\n","%cd /content/gdrive/My\\ Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild\n","from image_utils import *\n","%cd /content/gdrive/My\\ Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rfOqcHxLdUx2","colab_type":"code","outputId":"fdf5e734-595a-4547-cf56-8aef91f45e33","executionInfo":{"status":"ok","timestamp":1580882934590,"user_tz":480,"elapsed":816,"user":{"displayName":"ALEXANDER SAFONOV","photoUrl":"","userId":"06108573154481941124"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["# rgb_path = 'dataset/videos/frames/'+a1 +'/'+a2 +'/'+cur_file + '/'\n","root = '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents'\n","# path\n","train_path = root + '/dataset/features/training/' \n","test_path = root +  '/dataset/features/testing/' \n","\n","SEQ_LENGTH = 3\n","WIDTH = 416\n","HEIGHT = 128\n","STEPSIZE = 1\n","INPUT_DIR = './new_imgs/testing/'\n","OUTPUT_DIR = '/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/DenseDepth/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/'\n","\n","print(os.listdir('./'))\n","# dest = shutil.copy(source, destination)\n","\n","root_path = '/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code'\n","# source_path = root_path+'/accident_data/reformatting_imgs/final_outputs'\n","# destination_path = root_path + '/accident_data/reformatting_imgs/reordered_final_outputs'\n","\n","a1 = ['training', 'testing']\n","\n","## add path \n","optimal_crop_path = '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det/'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['.gitignore', '.travis.yml', 'CONTRIBUTING.md', 'LICENSE', 'README.md', '__init__.py', 'compile_protos.sh', 'depth_from_video_in_the_wild', '__pycache__', 'depth_checkpoints', 'lib', 'third_party']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kyAGE6n5kmGK","colab_type":"code","outputId":"6a9e4e96-a077-448a-8efb-31c260910263","executionInfo":{"status":"ok","timestamp":1580893005354,"user_tz":480,"elapsed":88284,"user":{"displayName":"ALEXANDER SAFONOV","photoUrl":"","userId":"06108573154481941124"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["## [1]: Create masks\n","# iterate through batches, for each video, if there are no masks, create masks from det file by create mask from bounding boxes and resizing\n","## training \n","from google.colab.patches import cv2_imshow\n","\n","num1 = (126, 46)\n","\n","mode1 = ['training' ,'testing' ]\n","path1 = [train_path, test_path]\n","\n","#dest_root_path = '/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/DenseDepth/google_distance_code/google_dist_code_1/google-research/depth_from_video_in_the_wild/data_example_1'\n","#dest_root_path = '/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/DenseDepth/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs/'\n","dest_root_path = '/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/'\n","resized_bb_path = '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det_2/' \n","## create numpy save file\n","for k in range(0,1):\n","  num = num1[k]\n","  mode = mode1[k]\n","  path = path1[k]\n","  det_path = resized_bb_path+mode+'/'\n","\n","  for num_batch in range(1,num+1):\n","      file_name = '%03d' %num_batch\n","      print(file_name)\n","      batch_data = np.load(path+'batch_'+file_name+'.npz', allow_pickle = True)\n","      batch_det = np.load(det_path+'batch_'+file_name+'.npz', allow_pickle = True)['new_det']\n","      batch_xs = batch_data['data']\n","      batch_ys = batch_data['labels']\n","      batch_ID = batch_data['ID']\n","      # batch_det = batch_data['det']\n","      frame_paths, frame_labels = retrieve_dir1(batch_ys, batch_ID, mode, num)\n","      # print('Frames:')\n","      # print(frame_paths)\n","      # print(frame_labels)\n","\n","      for vids in range(10):\n","        dest_path=dest_root_path+mode+'/'+re.split('/',frame_paths[vids])[-3]+'_'+re.split('/',frame_paths[vids])[-2]\n","\n","        print(dest_path)\n","        \n","        dest_path_subdir_list = os.listdir(dest_path)\n","  \n","\n","        if ('0000000001-fseg.png' in dest_path_subdir_list):\n","        # if False:\n","          pass\n","        else:\n","          print(dest_path)\n","          ## add if statement to get rid of folders that already have segmentation masks\n","\n","          for mask_frames in range(98):\n","            # cur_mask = np.zeros((720,1280))\n","            cur_mask = np.zeros((128, 416*3))\n","            for i in range(mask_frames, mask_frames+3):\n","              f_iter = i-mask_frames\n","              cur_bound_box = batch_det[vids,i,:,0:4]\n","              cur_bound_box = cur_bound_box[~np.all(cur_bound_box == 0, axis=1)]\n","              # print(cur_bound_box)\n","              for k in range(cur_bound_box.shape[0]):\n","                # if np.sum(cur_bound_box[k,:]) != 0:\n","                bb = cur_bound_box[k,:]\n","                cur_mask[int(bb[1]):int(bb[3]), int(bb[0]+f_iter*416):int(bb[2]+f_iter*416)] = 1\n","\n","\n","            # for mask_frames in range(0,100):\n","            #   mask_file_name = '%010d' %(mask_frames*3+1)+'_fseg.png'\n","            #   mask_path = dest_path+'/'+mask_file_name\n","            #   if os.path.exists(mask_path):\n","            #     os.remove(mask_path)\n"," \n","            mask_file_name = '%010d' %(mask_frames*3+1)+'-fseg.png'\n","            mask_path = dest_path+'/'+mask_file_name\n","\n","            \n","            if os.path.exists(mask_path):\n","              pass\n","              # img_shape = cv2.imread(mask_path).shape\n","              # if (img_shape[0] != 128 or img_shape[1] != 416*3):\n","              # if True:\n","              #   os.remove(mask_path)\n","              #   # print('Removed: '+str(mask_path))\n","              #   cropped = cur_mask\n","              #   cropped = cropped.astype('uint8')\n","              #   cv2.imwrite(mask_path, cropped * 255)\n","            else:\n","                cropped = cur_mask\n","                cropped = cropped.astype('uint8')\n","                cv2.imwrite(mask_path, cropped * 255)\n","                print(mask_path)\n","                # print(mask_path)\n","\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000331\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000620\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000646\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000604\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000344\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000347\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000619\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000337\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000320\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000305\n","101\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000643\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000607\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000338\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000673\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000670\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000343\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000603\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000334\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000617\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000684\n","102\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000345\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000341\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000688\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000685\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000674\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000626\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000652\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000618\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000605\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000690\n","103\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000306\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000327\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000660\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000666\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000693\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000639\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000651\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000609\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000642\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000653\n","104\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000700\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000309\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000302\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000314\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000637\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000316\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000650\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000644\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000636\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000627\n","105\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000681\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000675\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000691\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000699\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000613\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000672\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000322\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000333\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000606\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000615\n","106\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000778\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000789\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000385\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000780\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000761\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000386\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000361\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000357\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000744\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000779\n","107\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000393\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000374\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000730\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000767\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000718\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000358\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000741\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000734\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000379\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000799\n","108\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000369\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000770\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000354\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000758\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000792\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000793\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000769\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000395\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000729\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000391\n","109\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000756\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000791\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000740\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000735\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000764\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000401\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000384\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000785\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000731\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000801\n","110\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000389\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000728\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000747\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000368\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000373\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000794\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000353\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000714\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000732\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000760\n","111\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000705\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000755\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000722\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000364\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000737\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000773\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000387\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000356\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000711\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000774\n","112\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000702\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000768\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000771\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000378\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000382\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000749\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000790\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000720\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000400\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000782\n","113\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000371\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000359\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000383\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000738\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000388\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000726\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000719\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000363\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000775\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000372\n","114\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000757\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000703\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000763\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000390\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000748\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000776\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000375\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000772\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000736\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000781\n","115\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000759\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000733\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000380\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000355\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000796\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000398\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000751\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000713\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000399\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000367\n","116\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000723\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000743\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000396\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000765\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000742\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000724\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000370\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000710\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000788\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000365\n","117\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000717\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000739\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000754\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000766\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000381\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000786\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000362\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000800\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000377\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000707\n","118\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000721\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000746\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000784\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000783\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000752\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000706\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000360\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000392\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000797\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000753\n","119\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000795\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000352\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000376\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000725\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000762\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000798\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000397\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000745\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000777\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000715\n","120\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000712\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000708\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000787\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000727\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000716\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000709\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000366\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000750\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000394\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000704\n","121\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000343\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000825\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000336\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000380\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000820\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000817\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000371\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000366\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000334\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000828\n","122\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000829\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000819\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000821\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000332\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000802\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000804\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000385\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000811\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000351\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000341\n","123\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000372\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000001\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000345\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000370\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000337\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000813\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000375\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000379\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000354\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000356\n","124\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000342\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000349\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000823\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000812\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000824\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000822\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000335\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000355\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000350\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000358\n","125\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000376\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000353\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000805\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000815\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000368\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000363\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000818\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000362\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000810\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000381\n","126\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000346\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000364\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000382\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/negative_000807\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000374\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000352\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000383\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000367\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000339\n","/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/training/positive_000348\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ghm7QK5BUsk1","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","\n","def compile_file_list(self, data_dir, split, load_pose=False):\n","  \"\"\"Creates a list of input files.\"\"\"\n","  logging.info('data_dir: %s', data_dir)\n","  with tf.gfile.Open(os.path.join(data_dir, '%s.txt' % split), 'r') as f:\n","    frames = f.readlines()\n","    frames = [k.rstrip() for k in frames]\n","  subfolders = [x.split(' ')[0] for x in frames]\n","  frame_ids = [x.split(' ')[1] for x in frames]\n","  image_file_list = [\n","      os.path.join(data_dir, subfolders[i], frame_ids[i] + '.' +\n","                    self.file_extension)\n","      for i in range(len(frames))\n","  ]\n","  segment_file_list = [\n","      os.path.join(data_dir, subfolders[i], frame_ids[i] + '-fseg.' +\n","                    self.file_extension)\n","      for i in range(len(frames))\n","  ]\n","  cam_file_list = [\n","      os.path.join(data_dir, subfolders[i], frame_ids[i] + '_cam.txt')\n","      for i in range(len(frames))\n","  ]\n","  file_lists = {}\n","  file_lists['image_file_list'] = image_file_list\n","  file_lists['segment_file_list'] = segment_file_list\n","  file_lists['cam_file_list'] = cam_file_list\n","  if load_pose:\n","    pose_file_list = [\n","        os.path.join(data_dir, subfolders[i], frame_ids[i] + '_pose.txt')\n","        for i in range(len(frames))\n","    ]\n","    file_lists['pose_file_list'] = pose_file_list\n","  self.steps_per_epoch = len(image_file_list) // self.batch_size\n","  return file_lists"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WqKk-8zjHjcZ","colab_type":"text"},"source":["Process_depth_maps"]},{"cell_type":"code","metadata":{"id":"9cnbQZ56thMg","colab_type":"code","outputId":"df5b2658-f93b-4729-9764-106b4ce6fe96","executionInfo":{"status":"ok","timestamp":1579994608963,"user_tz":480,"elapsed":69469,"user":{"displayName":"ALEXANDER SAFONOV","photoUrl":"","userId":"06108573154481941124"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import tensorflow as tf\n","\n","!pip install tensorflow-graphics\n","\n","from depth_from_video_in_the_wild import model\n","\n","# tf.reset_default_graph() \n","train_model = model.Model(data_dir='./depth_from_video_in_the_wild/data_example',is_training=True)\n","saver  = train_model.saver\n","\n","# # saver = tf.train.Saver()\n","sess = tf.Session()\n","saver.restore(sess, save_path = './depth_from_video_in_the_wild/depth_cp_2/model-1000977')\n","\n","depth_model = model.Model(is_training=False, batch_size = 100)"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Collecting tensorflow-graphics\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/5d/b84b85322723aef25e5069596438a92dc7d5d1035ee11947e2105315eaa2/tensorflow_graphics-1.0.0-py2.py3-none-any.whl (243kB)\n","\r\u001b[K     |█▍                              | 10kB 28.5MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20kB 2.1MB/s eta 0:00:01\r\u001b[K     |████                            | 30kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 40kB 2.0MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 51kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████                        | 61kB 3.0MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 71kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 81kB 3.9MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 92kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 102kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 112kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 122kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 133kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 143kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 153kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 163kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 174kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 184kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 194kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 204kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 215kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 225kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 235kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 245kB 3.4MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow>=1.13.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-graphics) (1.15.0)\n","Requirement already satisfied: absl-py>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-graphics) (0.9.0)\n","Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-graphics) (1.12.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-graphics) (1.4.1)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow-graphics) (1.17.5)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.13.1->tensorflow-graphics) (0.8.1)\n","Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.13.1->tensorflow-graphics) (0.2.2)\n","Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.13.1->tensorflow-graphics) (1.15.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.13.1->tensorflow-graphics) (3.1.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.13.1->tensorflow-graphics) (0.33.6)\n","Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.13.1->tensorflow-graphics) (1.15.1)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.13.1->tensorflow-graphics) (0.1.8)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.13.1->tensorflow-graphics) (1.1.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.13.1->tensorflow-graphics) (1.15.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.13.1->tensorflow-graphics) (3.10.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.13.1->tensorflow-graphics) (1.1.0)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.13.1->tensorflow-graphics) (1.0.8)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.13.1->tensorflow-graphics) (1.11.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow>=1.13.1->tensorflow-graphics) (3.1.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow>=1.13.1->tensorflow-graphics) (0.16.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow>=1.13.1->tensorflow-graphics) (42.0.2)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow>=1.13.1->tensorflow-graphics) (2.8.0)\n","Installing collected packages: tensorflow-graphics\n","Successfully installed tensorflow-graphics-1.0.0\n"],"name":"stdout"},{"output_type":"stream","text":["Warning: To use the exr data format, please install the OpenEXR package following the instructions detailed in the README at github.com/tensorflow/graphics.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/reader.py:298: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/reader.py:298: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/reader.py:77: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/reader.py:77: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:277: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:277: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:189: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:189: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:198: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","To construct input pipelines, use the `tf.data` module.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:198: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","To construct input pipelines, use the `tf.data` module.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:198: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","To construct input pipelines, use the `tf.data` module.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:198: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","To construct input pipelines, use the `tf.data` module.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/reader.py:87: WholeFileReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.map(tf.read_file)`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/reader.py:87: WholeFileReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.map(tf.read_file)`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/reader.py:99: TextLineReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TextLineDataset`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/reader.py:99: TextLineReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TextLineDataset`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/reader.py:104: The name tf.decode_csv is deprecated. Please use tf.io.decode_csv instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/reader.py:104: The name tf.decode_csv is deprecated. Please use tf.io.decode_csv instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/reader.py:190: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/reader.py:190: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/reader.py:135: The name tf.matrix_inverse is deprecated. Please use tf.linalg.inv instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/reader.py:135: The name tf.matrix_inverse is deprecated. Please use tf.linalg.inv instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/reader.py:156: shuffle_batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.shuffle(min_after_dequeue).batch(batch_size)`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/reader.py:156: shuffle_batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.shuffle(min_after_dequeue).batch(batch_size)`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/model.py:167: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/model.py:167: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/model.py:182: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/model.py:182: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/model.py:183: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/model.py:183: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/model.py:185: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/model.py:185: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/model.py:204: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/model.py:204: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/model.py:204: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/model.py:204: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/depth_prediction_net.py:281: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/depth_prediction_net.py:281: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/depth_prediction_net.py:285: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/depth_prediction_net.py:285: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/depth_prediction_net.py:286: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/depth_prediction_net.py:286: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/depth_prediction_net.py:58: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/depth_prediction_net.py:58: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/depth_prediction_net.py:293: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/depth_prediction_net.py:293: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/normalization.py:327: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/normalization.py:327: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/motion_prediction_net.py:198: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/motion_prediction_net.py:198: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/model.py:289: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/model.py:289: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/transform_depth_map.py:298: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/transform_depth_map.py:298: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/consistency_losses.py:277: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/consistency_losses.py:277: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/model.py:114: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/model.py:114: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/model.py:117: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/model.py:117: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/model.py:346: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/model.py:346: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/model.py:371: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/model.py:371: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from ./depth_from_video_in_the_wild/depth_cp_2/model-1000977\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from ./depth_from_video_in_the_wild/depth_cp_2/model-1000977\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/model.py:378: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/model.py:378: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Scale of 0 disables regularizer.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Scale of 0 disables regularizer.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Scale of 0 disables regularizer.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Scale of 0 disables regularizer.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Scale of 0 disables regularizer.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Scale of 0 disables regularizer.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Scale of 0 disables regularizer.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Scale of 0 disables regularizer.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"fTuF0sYjF2Rp","colab_type":"text"},"source":["Depth inference from cropped images"]},{"cell_type":"code","metadata":{"id":"sMSR4Q4QHg3G","colab_type":"code","outputId":"d5d5d37f-5596-46aa-c443-41be6e59acde","executionInfo":{"status":"ok","timestamp":1580000941254,"user_tz":480,"elapsed":4660,"user":{"displayName":"ALEXANDER SAFONOV","photoUrl":"","userId":"06108573154481941124"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["str1 = ['training', 'testing']\n","str2 = ['positive','negative']\n","\n","# optimal_crop_path = '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det/'\n","# optimal_crop = np.load(optimal_crop_path+mode+'/'+'batch_'+file_name+'.npz')\n","#       batch_optimal_crop = optimal_crop['new_det']\n","\n","# output_base_root = '/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/depth_maps/720_1280_maps/'\n","output_base_root = '/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/depth_maps/distance_maps/'\n","\n","## three for loops, make outfile\n","# root_path = '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/'\n","root_path = '/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/'\n","\n","# path to optimal crops\n","optimal_crop_path = '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_det/' # shows the crops done for each image\n","\n","\n","for a1 in str1:\n","  # for a2 in str2: # this for loop is not needed\n","    # dir_list = sort_dir(os.listdir(root_path+a1+'/'+a2+'/'))]\n","  dir_list = sorted(os.listdir(root_path+a1+'/'))\n","  # files = glob.glob(folder + '/*.png')\n","  # files = [file for file in files if not 'disp' in file and not 'flip' in file and not 'seg' in file]\n","  # files = sorted(files)\n","  output_root = output_base_root#+a1+'/' #+a2+'/'\n","\n","  \n","  for a3 in dir_list:\n","    existing_list = sorted(os.listdir(output_root))  # Check which files were already created\n","\n","    curr_file = a3 + '.npz'\n","    \n","\n","    # if (curr_file in existing_list):\n","    if (curr_file in existing_list):\n","      print(curr_file)\n","      pass\n","    \n","    else:\n","      try:\n","        start_time = time.time()\n","        args_input = root_path+a1+'/'+a3+'/*.png'\n","        args_output = output_root+a3+'.npz'\n","        files_list = glob.glob(args_input)\n","        start_time = time.time()\n","\n","        sort_keys = h(obtain_keys1(files_list))\n","        r_files_list = [files_list[i] for i in sort_keys]\n","        \n","        # Input images\n","        ######\n","        img_stack = load_images( r_files_list ) ## change load_images so that it stacks 100 images, runs inference on entire video\n","        ######\n","\n","        print('Loaded: ' + root_path+a1+'/'+a3)\n","        distance_map = depth_model.inference_depth(img_stack, sess)\n","\n","        # outputs = predict(model, inputs)\n","        #### make code to save npy file in specified directory\n","        np.savez(args_output , distance_map=distance_map)\n","\n","        print('Saved file :' + str(args_output))\n","\n","        print(time.time() - start_time)\n","      except ValueError:\n","        # ValueError Signifies that there are not 100 frames. Should use shutil to delete the folder and recrop these images. Perhaps the videos are also shorter\n","        # if it is incorrect, delete the following folder and its contents:\n","        # root_path+a1+'/'+a3\n","\n","        # delete associated odometry files\n","        print('File Not Saved!!!')\n","        pass\n","\n","print(a1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["negative_000001.npz\n","negative_000002.npz\n","negative_000003.npz\n","negative_000004.npz\n","negative_000005.npz\n","negative_000006.npz\n","negative_000007.npz\n","negative_000008.npz\n","negative_000009.npz\n","negative_000010.npz\n","negative_000011.npz\n","negative_000012.npz\n","negative_000013.npz\n","negative_000014.npz\n","negative_000015.npz\n","negative_000016.npz\n","negative_000017.npz\n","negative_000018.npz\n","negative_000019.npz\n","negative_000020.npz\n","negative_000021.npz\n","negative_000022.npz\n","negative_000023.npz\n","negative_000024.npz\n","negative_000025.npz\n","negative_000026.npz\n","negative_000027.npz\n","negative_000028.npz\n","negative_000029.npz\n","negative_000030.npz\n","negative_000031.npz\n","negative_000032.npz\n","negative_000033.npz\n","negative_000034.npz\n","negative_000035.npz\n","negative_000036.npz\n","negative_000037.npz\n","negative_000038.npz\n","negative_000039.npz\n","negative_000040.npz\n","negative_000041.npz\n","negative_000042.npz\n","negative_000043.npz\n","negative_000044.npz\n","negative_000045.npz\n","negative_000046.npz\n","negative_000047.npz\n","negative_000048.npz\n","negative_000049.npz\n","negative_000050.npz\n","negative_000051.npz\n","negative_000052.npz\n","negative_000053.npz\n","negative_000054.npz\n","negative_000055.npz\n","negative_000056.npz\n","negative_000057.npz\n","negative_000058.npz\n","negative_000059.npz\n","negative_000060.npz\n","negative_000061.npz\n","negative_000062.npz\n","negative_000063.npz\n","negative_000064.npz\n","negative_000065.npz\n","negative_000066.npz\n","negative_000067.npz\n","negative_000068.npz\n","negative_000069.npz\n","negative_000070.npz\n","negative_000071.npz\n","negative_000072.npz\n","negative_000073.npz\n","negative_000074.npz\n","negative_000075.npz\n","negative_000076.npz\n","negative_000077.npz\n","negative_000078.npz\n","negative_000079.npz\n","negative_000080.npz\n","negative_000081.npz\n","negative_000082.npz\n","negative_000083.npz\n","negative_000084.npz\n","negative_000085.npz\n","negative_000086.npz\n","negative_000087.npz\n","negative_000088.npz\n","negative_000089.npz\n","negative_000090.npz\n","negative_000091.npz\n","negative_000092.npz\n","negative_000093.npz\n","negative_000094.npz\n","negative_000095.npz\n","negative_000096.npz\n","negative_000097.npz\n","negative_000098.npz\n","negative_000099.npz\n","negative_000100.npz\n","negative_000101.npz\n","negative_000102.npz\n","negative_000103.npz\n","negative_000104.npz\n","negative_000105.npz\n","negative_000106.npz\n","negative_000107.npz\n","negative_000108.npz\n","negative_000109.npz\n","negative_000110.npz\n","negative_000111.npz\n","negative_000112.npz\n","negative_000113.npz\n","negative_000114.npz\n","negative_000115.npz\n","negative_000116.npz\n","negative_000117.npz\n","negative_000118.npz\n","negative_000119.npz\n","negative_000120.npz\n","negative_000121.npz\n","negative_000122.npz\n","negative_000123.npz\n","negative_000124.npz\n","negative_000125.npz\n","negative_000126.npz\n","negative_000127.npz\n","negative_000128.npz\n","negative_000129.npz\n","negative_000130.npz\n","negative_000131.npz\n","negative_000132.npz\n","negative_000133.npz\n","negative_000134.npz\n","negative_000135.npz\n","negative_000136.npz\n","negative_000137.npz\n","negative_000138.npz\n","negative_000139.npz\n","negative_000140.npz\n","negative_000141.npz\n","negative_000142.npz\n","negative_000143.npz\n","negative_000144.npz\n","negative_000145.npz\n","negative_000146.npz\n","negative_000147.npz\n","negative_000148.npz\n","negative_000149.npz\n","negative_000150.npz\n","negative_000151.npz\n","negative_000152.npz\n","negative_000153.npz\n","negative_000154.npz\n","negative_000155.npz\n","negative_000156.npz\n","negative_000157.npz\n","negative_000158.npz\n","negative_000159.npz\n","negative_000160.npz\n","negative_000161.npz\n","negative_000162.npz\n","negative_000163.npz\n","negative_000164.npz\n","negative_000165.npz\n","negative_000166.npz\n","negative_000167.npz\n","negative_000168.npz\n","negative_000169.npz\n","negative_000170.npz\n","negative_000171.npz\n","negative_000172.npz\n","negative_000173.npz\n","negative_000174.npz\n","negative_000175.npz\n","negative_000176.npz\n","negative_000177.npz\n","negative_000178.npz\n","negative_000179.npz\n","negative_000180.npz\n","negative_000181.npz\n","negative_000182.npz\n","negative_000183.npz\n","negative_000184.npz\n","negative_000185.npz\n","negative_000186.npz\n","negative_000187.npz\n","negative_000188.npz\n","negative_000189.npz\n","negative_000190.npz\n","negative_000191.npz\n","negative_000192.npz\n","negative_000193.npz\n","negative_000194.npz\n","negative_000195.npz\n","negative_000196.npz\n","negative_000197.npz\n","negative_000198.npz\n","negative_000199.npz\n","negative_000200.npz\n","negative_000201.npz\n","negative_000202.npz\n","negative_000203.npz\n","negative_000204.npz\n","negative_000205.npz\n","negative_000206.npz\n","negative_000207.npz\n","negative_000208.npz\n","negative_000209.npz\n","negative_000210.npz\n","negative_000211.npz\n","negative_000212.npz\n","negative_000213.npz\n","negative_000214.npz\n","negative_000215.npz\n","negative_000216.npz\n","negative_000217.npz\n","negative_000218.npz\n","negative_000219.npz\n","negative_000220.npz\n","negative_000221.npz\n","negative_000222.npz\n","negative_000223.npz\n","negative_000224.npz\n","negative_000225.npz\n","negative_000226.npz\n","negative_000227.npz\n","negative_000228.npz\n","negative_000229.npz\n","negative_000230.npz\n","negative_000231.npz\n","negative_000232.npz\n","negative_000233.npz\n","negative_000234.npz\n","negative_000235.npz\n","negative_000236.npz\n","negative_000237.npz\n","negative_000238.npz\n","negative_000239.npz\n","negative_000240.npz\n","negative_000241.npz\n","negative_000242.npz\n","negative_000243.npz\n","negative_000244.npz\n","negative_000245.npz\n","negative_000246.npz\n","negative_000247.npz\n","negative_000248.npz\n","negative_000249.npz\n","negative_000250.npz\n","negative_000251.npz\n","negative_000252.npz\n","negative_000253.npz\n","negative_000254.npz\n","negative_000255.npz\n","negative_000256.npz\n","negative_000257.npz\n","negative_000258.npz\n","negative_000259.npz\n","negative_000260.npz\n","negative_000261.npz\n","negative_000262.npz\n","negative_000263.npz\n","negative_000264.npz\n","negative_000265.npz\n","negative_000266.npz\n","negative_000267.npz\n","negative_000268.npz\n","negative_000269.npz\n","negative_000270.npz\n","negative_000271.npz\n","negative_000272.npz\n","negative_000273.npz\n","negative_000274.npz\n","negative_000275.npz\n","negative_000276.npz\n","negative_000277.npz\n","negative_000278.npz\n","negative_000279.npz\n","negative_000280.npz\n","negative_000281.npz\n","negative_000282.npz\n","negative_000283.npz\n","negative_000284.npz\n","negative_000285.npz\n","negative_000286.npz\n","negative_000287.npz\n","negative_000288.npz\n","negative_000289.npz\n","negative_000290.npz\n","negative_000291.npz\n","negative_000292.npz\n","negative_000293.npz\n","negative_000294.npz\n","negative_000295.npz\n","negative_000296.npz\n","negative_000297.npz\n","negative_000298.npz\n","negative_000299.npz\n","negative_000300.npz\n","negative_000301.npz\n","negative_000302.npz\n","negative_000303.npz\n","negative_000304.npz\n","negative_000305.npz\n","negative_000306.npz\n","negative_000307.npz\n","negative_000308.npz\n","negative_000309.npz\n","negative_000310.npz\n","negative_000311.npz\n","negative_000312.npz\n","negative_000313.npz\n","negative_000314.npz\n","negative_000315.npz\n","negative_000316.npz\n","negative_000317.npz\n","negative_000318.npz\n","negative_000319.npz\n","negative_000320.npz\n","negative_000321.npz\n","negative_000322.npz\n","negative_000323.npz\n","negative_000324.npz\n","negative_000325.npz\n","negative_000326.npz\n","negative_000327.npz\n","negative_000328.npz\n","negative_000329.npz\n","negative_000330.npz\n","negative_000331.npz\n","negative_000332.npz\n","negative_000333.npz\n","negative_000334.npz\n","negative_000335.npz\n","negative_000336.npz\n","negative_000337.npz\n","negative_000338.npz\n","negative_000339.npz\n","negative_000340.npz\n","negative_000341.npz\n","negative_000342.npz\n","negative_000343.npz\n","negative_000344.npz\n","negative_000345.npz\n","negative_000346.npz\n","negative_000347.npz\n","negative_000348.npz\n","negative_000349.npz\n","negative_000350.npz\n","negative_000351.npz\n","negative_000352.npz\n","negative_000353.npz\n","negative_000354.npz\n","negative_000355.npz\n","negative_000356.npz\n","negative_000357.npz\n","negative_000358.npz\n","negative_000359.npz\n","negative_000360.npz\n","negative_000361.npz\n","negative_000362.npz\n","negative_000363.npz\n","negative_000364.npz\n","negative_000365.npz\n","negative_000366.npz\n","negative_000367.npz\n","negative_000368.npz\n","negative_000369.npz\n","negative_000370.npz\n","negative_000371.npz\n","negative_000372.npz\n","negative_000373.npz\n","negative_000374.npz\n","negative_000375.npz\n","negative_000376.npz\n","negative_000377.npz\n","negative_000378.npz\n","negative_000379.npz\n","negative_000380.npz\n","negative_000381.npz\n","negative_000382.npz\n","negative_000383.npz\n","negative_000384.npz\n","negative_000385.npz\n","negative_000386.npz\n","negative_000387.npz\n","negative_000388.npz\n","negative_000389.npz\n","negative_000390.npz\n","negative_000391.npz\n","negative_000392.npz\n","negative_000393.npz\n","negative_000394.npz\n","negative_000395.npz\n","negative_000396.npz\n","negative_000397.npz\n","negative_000398.npz\n","negative_000399.npz\n","negative_000400.npz\n","negative_000401.npz\n","negative_000402.npz\n","negative_000403.npz\n","negative_000404.npz\n","negative_000405.npz\n","negative_000406.npz\n","negative_000407.npz\n","negative_000408.npz\n","negative_000409.npz\n","negative_000410.npz\n","negative_000411.npz\n","negative_000412.npz\n","negative_000413.npz\n","negative_000414.npz\n","negative_000415.npz\n","negative_000416.npz\n","negative_000417.npz\n","negative_000418.npz\n","negative_000419.npz\n","negative_000420.npz\n","negative_000421.npz\n","negative_000422.npz\n","negative_000423.npz\n","negative_000424.npz\n","negative_000425.npz\n","negative_000426.npz\n","negative_000427.npz\n","negative_000428.npz\n","negative_000429.npz\n","negative_000430.npz\n","negative_000431.npz\n","negative_000432.npz\n","negative_000433.npz\n","negative_000434.npz\n","negative_000435.npz\n","negative_000436.npz\n","negative_000437.npz\n","negative_000438.npz\n","negative_000439.npz\n","negative_000440.npz\n","negative_000441.npz\n","negative_000442.npz\n","negative_000443.npz\n","negative_000444.npz\n","negative_000445.npz\n","negative_000446.npz\n","negative_000447.npz\n","negative_000448.npz\n","negative_000449.npz\n","negative_000450.npz\n","negative_000451.npz\n","negative_000452.npz\n","negative_000453.npz\n","negative_000454.npz\n","negative_000455.npz\n","negative_000456.npz\n","negative_000457.npz\n","negative_000458.npz\n","negative_000459.npz\n","negative_000460.npz\n","negative_000461.npz\n","negative_000462.npz\n","negative_000463.npz\n","negative_000464.npz\n","negative_000465.npz\n","negative_000466.npz\n","negative_000467.npz\n","negative_000468.npz\n","negative_000469.npz\n","negative_000470.npz\n","negative_000471.npz\n","negative_000472.npz\n","negative_000473.npz\n","negative_000474.npz\n","negative_000475.npz\n","negative_000476.npz\n","negative_000477.npz\n","negative_000478.npz\n","negative_000479.npz\n","negative_000480.npz\n","negative_000481.npz\n","negative_000482.npz\n","negative_000483.npz\n","negative_000484.npz\n","negative_000485.npz\n","negative_000486.npz\n","negative_000487.npz\n","negative_000488.npz\n","negative_000489.npz\n","negative_000490.npz\n","negative_000491.npz\n","negative_000492.npz\n","negative_000493.npz\n","negative_000494.npz\n","negative_000495.npz\n","negative_000496.npz\n","negative_000497.npz\n","negative_000498.npz\n","negative_000499.npz\n","negative_000500.npz\n","negative_000501.npz\n","negative_000502.npz\n","negative_000503.npz\n","negative_000504.npz\n","negative_000505.npz\n","negative_000506.npz\n","negative_000507.npz\n","negative_000508.npz\n","negative_000509.npz\n","negative_000510.npz\n","negative_000511.npz\n","negative_000512.npz\n","negative_000513.npz\n","negative_000514.npz\n","negative_000515.npz\n","negative_000516.npz\n","negative_000517.npz\n","negative_000518.npz\n","negative_000519.npz\n","negative_000520.npz\n","negative_000521.npz\n","negative_000522.npz\n","negative_000523.npz\n","negative_000524.npz\n","negative_000525.npz\n","negative_000526.npz\n","negative_000527.npz\n","negative_000528.npz\n","negative_000529.npz\n","negative_000530.npz\n","negative_000531.npz\n","negative_000532.npz\n","negative_000533.npz\n","negative_000534.npz\n","negative_000535.npz\n","negative_000536.npz\n","negative_000537.npz\n","negative_000538.npz\n","negative_000539.npz\n","negative_000540.npz\n","negative_000541.npz\n","negative_000542.npz\n","negative_000543.npz\n","negative_000544.npz\n","negative_000545.npz\n","negative_000546.npz\n","negative_000547.npz\n","negative_000548.npz\n","negative_000549.npz\n","negative_000550.npz\n","negative_000551.npz\n","negative_000552.npz\n","negative_000553.npz\n","negative_000554.npz\n","negative_000555.npz\n","negative_000556.npz\n","negative_000557.npz\n","negative_000558.npz\n","negative_000559.npz\n","negative_000560.npz\n","negative_000561.npz\n","negative_000562.npz\n","negative_000563.npz\n","negative_000564.npz\n","negative_000565.npz\n","negative_000566.npz\n","negative_000567.npz\n","negative_000568.npz\n","negative_000569.npz\n","negative_000570.npz\n","negative_000571.npz\n","negative_000572.npz\n","negative_000573.npz\n","negative_000574.npz\n","negative_000575.npz\n","negative_000576.npz\n","negative_000577.npz\n","negative_000578.npz\n","negative_000579.npz\n","negative_000580.npz\n","negative_000581.npz\n","negative_000582.npz\n","negative_000583.npz\n","negative_000584.npz\n","negative_000585.npz\n","negative_000586.npz\n","negative_000587.npz\n","negative_000588.npz\n","negative_000589.npz\n","negative_000590.npz\n","negative_000591.npz\n","negative_000592.npz\n","negative_000593.npz\n","negative_000594.npz\n","negative_000595.npz\n","negative_000596.npz\n","negative_000597.npz\n","negative_000598.npz\n","negative_000599.npz\n","negative_000600.npz\n","negative_000601.npz\n","negative_000602.npz\n","negative_000603.npz\n","negative_000604.npz\n","negative_000605.npz\n","negative_000606.npz\n","negative_000607.npz\n","negative_000608.npz\n","negative_000609.npz\n","negative_000610.npz\n","negative_000611.npz\n","negative_000612.npz\n","negative_000613.npz\n","negative_000614.npz\n","negative_000615.npz\n","negative_000616.npz\n","negative_000617.npz\n","negative_000618.npz\n","negative_000619.npz\n","negative_000620.npz\n","negative_000621.npz\n","negative_000622.npz\n","negative_000623.npz\n","negative_000624.npz\n","negative_000625.npz\n","negative_000626.npz\n","negative_000627.npz\n","negative_000628.npz\n","negative_000629.npz\n","negative_000630.npz\n","negative_000631.npz\n","negative_000632.npz\n","negative_000633.npz\n","negative_000634.npz\n","negative_000635.npz\n","negative_000636.npz\n","negative_000637.npz\n","negative_000638.npz\n","negative_000639.npz\n","negative_000640.npz\n","negative_000641.npz\n","negative_000642.npz\n","negative_000643.npz\n","negative_000644.npz\n","negative_000645.npz\n","negative_000646.npz\n","negative_000647.npz\n","negative_000648.npz\n","negative_000649.npz\n","negative_000650.npz\n","negative_000651.npz\n","negative_000652.npz\n","negative_000653.npz\n","negative_000654.npz\n","negative_000655.npz\n","negative_000656.npz\n","negative_000657.npz\n","negative_000658.npz\n","negative_000659.npz\n","negative_000660.npz\n","negative_000661.npz\n","negative_000662.npz\n","negative_000663.npz\n","negative_000664.npz\n","negative_000665.npz\n","negative_000666.npz\n","negative_000667.npz\n","negative_000668.npz\n","negative_000669.npz\n","negative_000670.npz\n","negative_000671.npz\n","negative_000672.npz\n","negative_000673.npz\n","negative_000674.npz\n","negative_000675.npz\n","negative_000676.npz\n","negative_000677.npz\n","negative_000678.npz\n","negative_000679.npz\n","negative_000680.npz\n","negative_000681.npz\n","negative_000682.npz\n","negative_000683.npz\n","negative_000684.npz\n","negative_000685.npz\n","negative_000686.npz\n","negative_000687.npz\n","negative_000688.npz\n","negative_000689.npz\n","negative_000690.npz\n","negative_000691.npz\n","negative_000692.npz\n","negative_000693.npz\n","negative_000694.npz\n","negative_000695.npz\n","negative_000696.npz\n","negative_000697.npz\n","negative_000698.npz\n","negative_000699.npz\n","negative_000700.npz\n","negative_000701.npz\n","negative_000702.npz\n","negative_000703.npz\n","negative_000704.npz\n","negative_000705.npz\n","negative_000706.npz\n","negative_000707.npz\n","negative_000708.npz\n","negative_000709.npz\n","negative_000710.npz\n","negative_000711.npz\n","negative_000712.npz\n","negative_000713.npz\n","negative_000714.npz\n","negative_000715.npz\n","negative_000716.npz\n","negative_000717.npz\n","negative_000718.npz\n","negative_000719.npz\n","negative_000720.npz\n","negative_000721.npz\n","negative_000722.npz\n","negative_000723.npz\n","negative_000724.npz\n","negative_000725.npz\n","negative_000726.npz\n","negative_000727.npz\n","negative_000728.npz\n","negative_000729.npz\n","negative_000730.npz\n","negative_000731.npz\n","negative_000732.npz\n","negative_000733.npz\n","negative_000734.npz\n","negative_000735.npz\n","negative_000736.npz\n","negative_000737.npz\n","negative_000738.npz\n","negative_000739.npz\n","negative_000740.npz\n","negative_000741.npz\n","negative_000742.npz\n","negative_000743.npz\n","negative_000744.npz\n","negative_000745.npz\n","negative_000746.npz\n","negative_000747.npz\n","negative_000748.npz\n","negative_000749.npz\n","negative_000750.npz\n","negative_000751.npz\n","negative_000752.npz\n","negative_000753.npz\n","negative_000754.npz\n","negative_000755.npz\n","negative_000756.npz\n","negative_000757.npz\n","negative_000758.npz\n","negative_000759.npz\n","negative_000760.npz\n","negative_000761.npz\n","negative_000762.npz\n","negative_000763.npz\n","negative_000764.npz\n","negative_000765.npz\n","negative_000766.npz\n","negative_000767.npz\n","negative_000768.npz\n","negative_000769.npz\n","negative_000770.npz\n","negative_000771.npz\n","negative_000772.npz\n","negative_000773.npz\n","negative_000774.npz\n","negative_000775.npz\n","negative_000776.npz\n","negative_000777.npz\n","negative_000778.npz\n","negative_000779.npz\n","negative_000780.npz\n","negative_000781.npz\n","negative_000782.npz\n","negative_000783.npz\n","negative_000784.npz\n","negative_000785.npz\n","negative_000786.npz\n","negative_000787.npz\n","negative_000788.npz\n","negative_000789.npz\n","negative_000790.npz\n","negative_000791.npz\n","negative_000792.npz\n","negative_000793.npz\n","negative_000794.npz\n","negative_000795.npz\n","negative_000796.npz\n","negative_000797.npz\n","negative_000798.npz\n","negative_000799.npz\n","negative_000800.npz\n","negative_000801.npz\n","negative_000802.npz\n","negative_000804.npz\n","negative_000805.npz\n","negative_000807.npz\n","negative_000810.npz\n","negative_000811.npz\n","negative_000812.npz\n","negative_000813.npz\n","negative_000815.npz\n","negative_000817.npz\n","negative_000818.npz\n","negative_000819.npz\n","negative_000820.npz\n","negative_000821.npz\n","negative_000822.npz\n","negative_000823.npz\n","negative_000824.npz\n","negative_000825.npz\n","negative_000828.npz\n","negative_000829.npz\n","positive_000002.npz\n","positive_000003.npz\n","positive_000004.npz\n","positive_000005.npz\n","positive_000006.npz\n","positive_000007.npz\n","positive_000008.npz\n","positive_000009.npz\n","positive_000010.npz\n","positive_000011.npz\n","positive_000012.npz\n","positive_000013.npz\n","positive_000014.npz\n","positive_000015.npz\n","positive_000016.npz\n","positive_000017.npz\n","positive_000018.npz\n","positive_000019.npz\n","positive_000020.npz\n","positive_000021.npz\n","positive_000022.npz\n","positive_000023.npz\n","positive_000024.npz\n","positive_000025.npz\n","positive_000026.npz\n","positive_000027.npz\n","positive_000028.npz\n","positive_000029.npz\n","positive_000030.npz\n","positive_000031.npz\n","positive_000032.npz\n","positive_000033.npz\n","positive_000034.npz\n","positive_000035.npz\n","positive_000036.npz\n","positive_000037.npz\n","positive_000038.npz\n","positive_000039.npz\n","positive_000040.npz\n","positive_000041.npz\n","positive_000042.npz\n","positive_000043.npz\n","positive_000044.npz\n","positive_000045.npz\n","positive_000046.npz\n","positive_000047.npz\n","positive_000048.npz\n","positive_000049.npz\n","positive_000050.npz\n","positive_000051.npz\n","positive_000052.npz\n","positive_000053.npz\n","positive_000054.npz\n","positive_000055.npz\n","positive_000056.npz\n","positive_000057.npz\n","positive_000058.npz\n","positive_000059.npz\n","positive_000060.npz\n","positive_000061.npz\n","positive_000062.npz\n","positive_000063.npz\n","positive_000064.npz\n","positive_000065.npz\n","positive_000066.npz\n","positive_000067.npz\n","positive_000068.npz\n","positive_000069.npz\n","positive_000070.npz\n","positive_000071.npz\n","positive_000072.npz\n","positive_000073.npz\n","positive_000074.npz\n","positive_000075.npz\n","positive_000076.npz\n","positive_000077.npz\n","positive_000078.npz\n","positive_000079.npz\n","positive_000080.npz\n","positive_000081.npz\n","positive_000082.npz\n","positive_000083.npz\n","positive_000084.npz\n","positive_000085.npz\n","positive_000086.npz\n","positive_000087.npz\n","positive_000088.npz\n","positive_000089.npz\n","positive_000090.npz\n","positive_000091.npz\n","positive_000092.npz\n","positive_000093.npz\n","positive_000094.npz\n","positive_000095.npz\n","positive_000096.npz\n","positive_000097.npz\n","positive_000098.npz\n","positive_000099.npz\n","positive_000100.npz\n","positive_000101.npz\n","positive_000102.npz\n","positive_000103.npz\n","positive_000104.npz\n","positive_000105.npz\n","positive_000106.npz\n","positive_000107.npz\n","positive_000108.npz\n","positive_000109.npz\n","positive_000110.npz\n","positive_000111.npz\n","positive_000112.npz\n","positive_000113.npz\n","positive_000114.npz\n","positive_000115.npz\n","positive_000116.npz\n","positive_000117.npz\n","positive_000118.npz\n","positive_000119.npz\n","positive_000120.npz\n","positive_000121.npz\n","positive_000122.npz\n","positive_000123.npz\n","positive_000124.npz\n","positive_000125.npz\n","positive_000126.npz\n","positive_000127.npz\n","positive_000128.npz\n","positive_000129.npz\n","positive_000130.npz\n","positive_000131.npz\n","positive_000132.npz\n","positive_000133.npz\n","positive_000134.npz\n","positive_000135.npz\n","positive_000136.npz\n","positive_000137.npz\n","positive_000138.npz\n","positive_000139.npz\n","positive_000140.npz\n","positive_000141.npz\n","positive_000142.npz\n","positive_000143.npz\n","positive_000144.npz\n","positive_000145.npz\n","positive_000146.npz\n","positive_000147.npz\n","positive_000148.npz\n","positive_000149.npz\n","positive_000150.npz\n","positive_000151.npz\n","positive_000152.npz\n","positive_000153.npz\n","positive_000154.npz\n","positive_000155.npz\n","positive_000156.npz\n","positive_000157.npz\n","positive_000158.npz\n","positive_000159.npz\n","positive_000160.npz\n","positive_000161.npz\n","positive_000162.npz\n","positive_000163.npz\n","positive_000164.npz\n","positive_000165.npz\n","positive_000166.npz\n","positive_000167.npz\n","positive_000168.npz\n","positive_000169.npz\n","positive_000170.npz\n","positive_000171.npz\n","positive_000172.npz\n","positive_000173.npz\n","positive_000174.npz\n","positive_000175.npz\n","positive_000176.npz\n","positive_000177.npz\n","positive_000178.npz\n","positive_000179.npz\n","positive_000180.npz\n","positive_000181.npz\n","positive_000182.npz\n","positive_000183.npz\n","positive_000184.npz\n","positive_000185.npz\n","positive_000186.npz\n","positive_000187.npz\n","positive_000188.npz\n","positive_000189.npz\n","positive_000190.npz\n","positive_000191.npz\n","positive_000192.npz\n","positive_000193.npz\n","positive_000194.npz\n","positive_000195.npz\n","positive_000196.npz\n","positive_000197.npz\n","positive_000198.npz\n","positive_000199.npz\n","positive_000200.npz\n","positive_000201.npz\n","positive_000202.npz\n","positive_000203.npz\n","positive_000204.npz\n","positive_000205.npz\n","positive_000206.npz\n","positive_000207.npz\n","positive_000208.npz\n","positive_000209.npz\n","positive_000210.npz\n","positive_000211.npz\n","positive_000212.npz\n","positive_000213.npz\n","positive_000214.npz\n","positive_000215.npz\n","positive_000216.npz\n","positive_000217.npz\n","positive_000218.npz\n","positive_000219.npz\n","positive_000220.npz\n","positive_000221.npz\n","positive_000222.npz\n","positive_000223.npz\n","positive_000224.npz\n","positive_000225.npz\n","positive_000226.npz\n","positive_000227.npz\n","positive_000228.npz\n","positive_000229.npz\n","positive_000230.npz\n","positive_000231.npz\n","positive_000232.npz\n","positive_000233.npz\n","positive_000234.npz\n","positive_000235.npz\n","positive_000236.npz\n","positive_000237.npz\n","positive_000238.npz\n","positive_000239.npz\n","positive_000240.npz\n","positive_000241.npz\n","positive_000242.npz\n","positive_000243.npz\n","positive_000244.npz\n","positive_000245.npz\n","positive_000246.npz\n","positive_000247.npz\n","positive_000248.npz\n","positive_000249.npz\n","positive_000250.npz\n","positive_000251.npz\n","positive_000252.npz\n","positive_000253.npz\n","positive_000254.npz\n","positive_000255.npz\n","positive_000256.npz\n","positive_000257.npz\n","positive_000258.npz\n","positive_000259.npz\n","positive_000260.npz\n","positive_000261.npz\n","positive_000262.npz\n","positive_000263.npz\n","positive_000264.npz\n","positive_000265.npz\n","positive_000266.npz\n","positive_000267.npz\n","positive_000268.npz\n","positive_000269.npz\n","positive_000270.npz\n","positive_000271.npz\n","positive_000272.npz\n","positive_000273.npz\n","positive_000274.npz\n","positive_000275.npz\n","positive_000276.npz\n","positive_000277.npz\n","positive_000278.npz\n","positive_000279.npz\n","positive_000280.npz\n","positive_000281.npz\n","positive_000282.npz\n","positive_000283.npz\n","positive_000284.npz\n","positive_000285.npz\n","positive_000286.npz\n","positive_000287.npz\n","positive_000288.npz\n","positive_000289.npz\n","positive_000290.npz\n","positive_000291.npz\n","positive_000292.npz\n","positive_000293.npz\n","positive_000294.npz\n","positive_000295.npz\n","positive_000296.npz\n","positive_000297.npz\n","positive_000298.npz\n","positive_000299.npz\n","positive_000300.npz\n","positive_000301.npz\n","positive_000302.npz\n","positive_000303.npz\n","positive_000304.npz\n","positive_000305.npz\n","positive_000306.npz\n","positive_000307.npz\n","positive_000308.npz\n","positive_000309.npz\n","positive_000310.npz\n","positive_000311.npz\n","positive_000312.npz\n","positive_000313.npz\n","positive_000314.npz\n","positive_000315.npz\n","positive_000316.npz\n","positive_000317.npz\n","positive_000318.npz\n","positive_000319.npz\n","positive_000320.npz\n","positive_000321.npz\n","positive_000322.npz\n","positive_000323.npz\n","positive_000324.npz\n","positive_000325.npz\n","positive_000326.npz\n","positive_000327.npz\n","positive_000328.npz\n","positive_000329.npz\n","positive_000330.npz\n","positive_000331.npz\n","positive_000332.npz\n","positive_000333.npz\n","positive_000334.npz\n","positive_000335.npz\n","positive_000336.npz\n","positive_000337.npz\n","positive_000338.npz\n","positive_000339.npz\n","positive_000340.npz\n","positive_000341.npz\n","positive_000342.npz\n","positive_000343.npz\n","positive_000344.npz\n","positive_000345.npz\n","positive_000346.npz\n","positive_000347.npz\n","positive_000348.npz\n","positive_000349.npz\n","positive_000350.npz\n","positive_000351.npz\n","positive_000352.npz\n","positive_000353.npz\n","positive_000354.npz\n","positive_000355.npz\n","positive_000356.npz\n","positive_000357.npz\n","positive_000358.npz\n","positive_000359.npz\n","positive_000360.npz\n","positive_000361.npz\n","positive_000362.npz\n","positive_000363.npz\n","positive_000364.npz\n","positive_000365.npz\n","positive_000366.npz\n","positive_000367.npz\n","positive_000368.npz\n","positive_000369.npz\n","positive_000370.npz\n","positive_000371.npz\n","positive_000372.npz\n","positive_000373.npz\n","positive_000374.npz\n","positive_000375.npz\n","positive_000376.npz\n","positive_000377.npz\n","positive_000378.npz\n","positive_000379.npz\n","positive_000380.npz\n","positive_000381.npz\n","positive_000382.npz\n","positive_000383.npz\n","positive_000384.npz\n","positive_000385.npz\n","positive_000386.npz\n","positive_000387.npz\n","positive_000388.npz\n","positive_000389.npz\n","positive_000390.npz\n","positive_000391.npz\n","positive_000392.npz\n","positive_000393.npz\n","positive_000394.npz\n","positive_000395.npz\n","positive_000396.npz\n","positive_000397.npz\n","positive_000398.npz\n","positive_000399.npz\n","positive_000400.npz\n","positive_000401.npz\n","negative_000830.npz\n","negative_000831.npz\n","negative_000832.npz\n","negative_000833.npz\n","negative_000834.npz\n","negative_000835.npz\n","negative_000836.npz\n","negative_000837.npz\n","negative_000838.npz\n","negative_000839.npz\n","negative_000840.npz\n","negative_000841.npz\n","negative_000842.npz\n","negative_000843.npz\n","negative_000844.npz\n","negative_000845.npz\n","negative_000846.npz\n","negative_000847.npz\n","negative_000848.npz\n","negative_000849.npz\n","negative_000850.npz\n","negative_000851.npz\n","negative_000852.npz\n","negative_000853.npz\n","negative_000854.npz\n","negative_000855.npz\n","negative_000856.npz\n","negative_000857.npz\n","negative_000858.npz\n","negative_000859.npz\n","negative_000860.npz\n","negative_000861.npz\n","negative_000862.npz\n","negative_000863.npz\n","negative_000864.npz\n","negative_000865.npz\n","negative_000866.npz\n","negative_000867.npz\n","negative_000868.npz\n","negative_000869.npz\n","negative_000870.npz\n","negative_000871.npz\n","negative_000872.npz\n","negative_000873.npz\n","negative_000874.npz\n","negative_000875.npz\n","negative_000876.npz\n","negative_000877.npz\n","negative_000878.npz\n","negative_000879.npz\n","negative_000880.npz\n","negative_000881.npz\n","negative_000882.npz\n","negative_000883.npz\n","negative_000884.npz\n","negative_000885.npz\n","negative_000886.npz\n","negative_000887.npz\n","negative_000888.npz\n","negative_000889.npz\n","negative_000890.npz\n","negative_000891.npz\n","negative_000892.npz\n","negative_000893.npz\n","negative_000894.npz\n","negative_000895.npz\n","negative_000896.npz\n","negative_000897.npz\n","negative_000898.npz\n","negative_000899.npz\n","negative_000900.npz\n","negative_000901.npz\n","negative_000902.npz\n","negative_000903.npz\n","negative_000904.npz\n","negative_000905.npz\n","negative_000906.npz\n","negative_000907.npz\n","negative_000908.npz\n","negative_000909.npz\n","negative_000910.npz\n","negative_000911.npz\n","negative_000912.npz\n","negative_000913.npz\n","negative_000914.npz\n","negative_000915.npz\n","negative_000916.npz\n","negative_000917.npz\n","negative_000918.npz\n","negative_000919.npz\n","negative_000920.npz\n","negative_000921.npz\n","negative_000922.npz\n","negative_000923.npz\n","negative_000924.npz\n","negative_000925.npz\n","negative_000926.npz\n","negative_000927.npz\n","negative_000928.npz\n","negative_000929.npz\n","negative_000930.npz\n","negative_000931.npz\n","negative_000932.npz\n","negative_000933.npz\n","negative_000934.npz\n","negative_000935.npz\n","negative_000936.npz\n","negative_000937.npz\n","negative_000938.npz\n","negative_000939.npz\n","negative_000940.npz\n","negative_000941.npz\n","negative_000942.npz\n","negative_000943.npz\n","negative_000944.npz\n","negative_000945.npz\n","negative_000946.npz\n","negative_000947.npz\n","negative_000948.npz\n","negative_000949.npz\n","negative_000950.npz\n","negative_000951.npz\n","negative_000952.npz\n","negative_000953.npz\n","negative_000954.npz\n","negative_000955.npz\n","negative_000956.npz\n","negative_000957.npz\n","negative_000958.npz\n","negative_000959.npz\n","negative_000960.npz\n","negative_000961.npz\n","negative_000962.npz\n","negative_000963.npz\n","negative_000964.npz\n","negative_000965.npz\n","negative_000966.npz\n","negative_000967.npz\n","negative_000968.npz\n","negative_000969.npz\n","negative_000970.npz\n","negative_000971.npz\n","negative_000972.npz\n","negative_000973.npz\n","negative_000974.npz\n","negative_000975.npz\n","negative_000976.npz\n","negative_000977.npz\n","negative_000978.npz\n","negative_000979.npz\n","negative_000980.npz\n","negative_000981.npz\n","negative_000982.npz\n","negative_000983.npz\n","negative_000984.npz\n","negative_000985.npz\n","negative_000986.npz\n","negative_000987.npz\n","negative_000988.npz\n","negative_000989.npz\n","negative_000990.npz\n","negative_000991.npz\n","negative_000992.npz\n","negative_000993.npz\n","negative_000994.npz\n","negative_000995.npz\n","negative_000996.npz\n","negative_000997.npz\n","negative_000998.npz\n","negative_000999.npz\n","negative_001000.npz\n","negative_001001.npz\n","negative_001002.npz\n","negative_001003.npz\n","negative_001004.npz\n","negative_001005.npz\n","negative_001006.npz\n","negative_001007.npz\n","negative_001008.npz\n","negative_001009.npz\n","negative_001010.npz\n","negative_001011.npz\n","negative_001012.npz\n","negative_001013.npz\n","negative_001014.npz\n","negative_001015.npz\n","negative_001016.npz\n","negative_001017.npz\n","negative_001018.npz\n","negative_001019.npz\n","negative_001020.npz\n","negative_001021.npz\n","negative_001022.npz\n","negative_001023.npz\n","negative_001024.npz\n","negative_001025.npz\n","negative_001026.npz\n","negative_001027.npz\n","negative_001028.npz\n","negative_001029.npz\n","negative_001030.npz\n","negative_001031.npz\n","negative_001032.npz\n","negative_001033.npz\n","negative_001034.npz\n","negative_001035.npz\n","negative_001036.npz\n","negative_001037.npz\n","negative_001038.npz\n","negative_001039.npz\n","negative_001040.npz\n","negative_001041.npz\n","negative_001042.npz\n","negative_001043.npz\n","negative_001044.npz\n","negative_001045.npz\n","negative_001046.npz\n","negative_001047.npz\n","negative_001048.npz\n","negative_001049.npz\n","negative_001050.npz\n","negative_001051.npz\n","negative_001052.npz\n","negative_001053.npz\n","negative_001054.npz\n","negative_001055.npz\n","negative_001056.npz\n","negative_001057.npz\n","negative_001058.npz\n","negative_001059.npz\n","negative_001060.npz\n","negative_001061.npz\n","negative_001062.npz\n","negative_001063.npz\n","negative_001064.npz\n","negative_001065.npz\n","negative_001066.npz\n","negative_001067.npz\n","negative_001068.npz\n","negative_001069.npz\n","negative_001070.npz\n","negative_001071.npz\n","negative_001072.npz\n","negative_001073.npz\n","negative_001074.npz\n","negative_001075.npz\n","negative_001076.npz\n","negative_001077.npz\n","negative_001078.npz\n","negative_001079.npz\n","negative_001080.npz\n","negative_001081.npz\n","negative_001082.npz\n","negative_001083.npz\n","negative_001084.npz\n","negative_001085.npz\n","negative_001086.npz\n","negative_001087.npz\n","negative_001088.npz\n","negative_001089.npz\n","negative_001090.npz\n","negative_001091.npz\n","negative_001092.npz\n","negative_001093.npz\n","negative_001094.npz\n","negative_001095.npz\n","negative_001096.npz\n","negative_001097.npz\n","negative_001098.npz\n","negative_001099.npz\n","negative_001100.npz\n","negative_001101.npz\n","negative_001102.npz\n","negative_001103.npz\n","negative_001104.npz\n","negative_001105.npz\n","negative_001106.npz\n","negative_001107.npz\n","negative_001108.npz\n","negative_001109.npz\n","negative_001110.npz\n","negative_001111.npz\n","negative_001112.npz\n","negative_001113.npz\n","negative_001114.npz\n","negative_001115.npz\n","negative_001116.npz\n","negative_001117.npz\n","negative_001118.npz\n","negative_001119.npz\n","negative_001120.npz\n","negative_001121.npz\n","negative_001122.npz\n","negative_001123.npz\n","negative_001124.npz\n","negative_001125.npz\n","negative_001126.npz\n","negative_001127.npz\n","negative_001128.npz\n","negative_001129.npz\n","negative_001130.npz\n","positive_000457.npz\n","positive_000458.npz\n","positive_000459.npz\n","positive_000460.npz\n","positive_000461.npz\n","positive_000462.npz\n","positive_000463.npz\n","positive_000464.npz\n","positive_000465.npz\n","positive_000466.npz\n","positive_000467.npz\n","positive_000468.npz\n","positive_000469.npz\n","positive_000470.npz\n","positive_000471.npz\n","positive_000472.npz\n","positive_000473.npz\n","positive_000474.npz\n","positive_000475.npz\n","positive_000476.npz\n","positive_000477.npz\n","positive_000478.npz\n","positive_000479.npz\n","positive_000480.npz\n","positive_000481.npz\n","positive_000482.npz\n","positive_000483.npz\n","positive_000484.npz\n","positive_000485.npz\n","positive_000486.npz\n","positive_000487.npz\n","positive_000488.npz\n","positive_000489.npz\n","positive_000490.npz\n","positive_000491.npz\n","positive_000492.npz\n","positive_000493.npz\n","positive_000494.npz\n","positive_000495.npz\n","positive_000496.npz\n","positive_000497.npz\n","positive_000498.npz\n","positive_000499.npz\n","positive_000500.npz\n","positive_000501.npz\n","positive_000502.npz\n","positive_000503.npz\n","positive_000504.npz\n","positive_000505.npz\n","positive_000506.npz\n","positive_000507.npz\n","positive_000508.npz\n","positive_000509.npz\n","positive_000510.npz\n","positive_000511.npz\n","positive_000512.npz\n","positive_000513.npz\n","positive_000514.npz\n","positive_000515.npz\n","positive_000516.npz\n","positive_000517.npz\n","positive_000518.npz\n","positive_000519.npz\n","positive_000520.npz\n","positive_000521.npz\n","positive_000522.npz\n","positive_000523.npz\n","positive_000524.npz\n","positive_000525.npz\n","positive_000526.npz\n","positive_000527.npz\n","positive_000528.npz\n","positive_000529.npz\n","positive_000530.npz\n","positive_000531.npz\n","positive_000532.npz\n","positive_000533.npz\n","positive_000534.npz\n","positive_000535.npz\n","positive_000536.npz\n","positive_000537.npz\n","positive_000538.npz\n","positive_000539.npz\n","positive_000540.npz\n","positive_000541.npz\n","positive_000542.npz\n","positive_000543.npz\n","positive_000544.npz\n","positive_000545.npz\n","positive_000546.npz\n","positive_000547.npz\n","positive_000548.npz\n","positive_000549.npz\n","positive_000550.npz\n","positive_000551.npz\n","positive_000552.npz\n","positive_000553.npz\n","positive_000554.npz\n","positive_000555.npz\n","positive_000556.npz\n","positive_000557.npz\n","positive_000558.npz\n","positive_000559.npz\n","positive_000560.npz\n","positive_000561.npz\n","positive_000562.npz\n","positive_000563.npz\n","positive_000564.npz\n","positive_000565.npz\n","positive_000566.npz\n","positive_000567.npz\n","positive_000568.npz\n","positive_000569.npz\n","positive_000570.npz\n","positive_000571.npz\n","positive_000572.npz\n","positive_000573.npz\n","positive_000574.npz\n","positive_000575.npz\n","positive_000576.npz\n","positive_000577.npz\n","positive_000578.npz\n","positive_000579.npz\n","positive_000580.npz\n","positive_000581.npz\n","positive_000582.npz\n","positive_000583.npz\n","positive_000584.npz\n","positive_000585.npz\n","positive_000586.npz\n","positive_000587.npz\n","positive_000588.npz\n","positive_000589.npz\n","positive_000590.npz\n","positive_000591.npz\n","positive_000592.npz\n","positive_000593.npz\n","positive_000594.npz\n","positive_000595.npz\n","positive_000596.npz\n","positive_000597.npz\n","positive_000598.npz\n","positive_000599.npz\n","positive_000600.npz\n","positive_000601.npz\n","positive_000602.npz\n","positive_000603.npz\n","positive_000604.npz\n","positive_000605.npz\n","positive_000606.npz\n","testing\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XMSYtxQOGcyP","colab_type":"text"},"source":["import shutil\n","Previous function for cropping code"]},{"cell_type":"code","metadata":{"id":"45qyX_C-_Uj9","colab_type":"code","colab":{}},"source":["import shutil\n","\n","path_odom = '/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/odometry_trajectory_outputs/'\n","\n","# crop_type\n","# delete path_odom files for each folder create\n","# odometry_negative_XXXXXX.npz\n","\n","def run_all(mode='training'):\n","  ct = 0\n","  # INPUT_DIR\n","\n","  # odometry output\n","  INPUT_DIR = '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/'+mode+'/'\n","  OUTPUT_DIR = '/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/'+mode+'/'\n","  if not OUTPUT_DIR.endswith('/'):\n","      OUTPUT_DIR = OUTPUT_DIR + '/'\n","\n","  ## d is positive or negative\n","  for d in glob.glob(INPUT_DIR + '/*/'):\n","      date = d.split('/')[-2]\n","      # file_calibration = d + 'calib_cam_to_cam.txt'\n","      ## d2 is the actual folder creating the file sequence\n","      for d2 in glob.glob(d + '*/'):\n","          seqname = d2.split('/')[-2]\n","          # print('Processing sequence', seqname)\n","          # for subfolder in ['image_02/data', 'image_03/data']:\n","          ct = 1\n","          # image_0 is a subfolder of the sequence\n","          # print(OUTPUT_DIR+date+'_'+seqname)\n","\n","\n","          if not os.path.exists(OUTPUT_DIR +date+'_'+seqname):\n","            os.mkdir(OUTPUT_DIR +'/'+date+'_'+ seqname)\n","          if True:\n","              # print('made dir ' +date+'_'+ seqname)\n","              # calib_camera = calib_raw[0] if subfolder=='image_02/data' else calib_raw[1]\n","              folder = OUTPUT_DIR +date+'_'+seqname # negative_number\n","              # print(folder)\n","              files = glob.glob(folder + '/*.png')\n","              files = [file for file in files if not 'disp' in file and not 'flip' in file and not 'seg' in file]\n","              files = sorted(files)\n","              if len(files) != 98:\n","                print('Removing!')\n","                print(folder)\n","                shutil.rmtree(folder)\n","                # remove odometry at certain points where points were cropped incorrectly\n","\n","              continue\n","              if os.path.exists(folder):\n","                pass\n","              else:\n","                for i in range(SEQ_LENGTH, len(files)+1, STEPSIZE):\n","                    imgnum = str(ct).zfill(10)\n","                    # if os.path.exists(OUTPUT_DIR + seqname + '/' + imgnum + '.png'):\n","                    #     ct+=1\n","                    #     continue\n","                    big_img = np.zeros(shape=(HEIGHT, WIDTH*SEQ_LENGTH, 3))\n","                    wct = 0\n","\n","                    for j in range(i-SEQ_LENGTH, i):  # Collect frames for this sample.\n","                        img = cv2.imread(files[j])\n","                        \n","                        ORIGINAL_HEIGHT, ORIGINAL_WIDTH, _ = img.shape\n","\n","                        #### Crops\n","                        cropped = crop(img)\n","                        if (np.abs(cropped.shape[0]-128)>30) and (np.abs(cropped.shape[1]-416)>30):\n","                            x_1 = np.zeros((720,1280, 3))\n","                            x_1[0:x.shape[0], 0:x.shape[1], :] = x  \n","\n","                            #### Crops\n","                            cropped = crop(x_1)\n","\n","                        zoom_x = WIDTH/ORIGINAL_WIDTH\n","                        zoom_y = HEIGHT/ORIGINAL_HEIGHT\n","\n","                        img = cv2.resize(cropped, (WIDTH, HEIGHT))\n","                        big_img[:,wct*WIDTH:(wct+1)*WIDTH] = img\n","                        wct+=1\n","                        cv2.imwrite(OUTPUT_DIR+date +'_'+ seqname + '/' + imgnum + '.png', big_img)\n","                        f = open(OUTPUT_DIR +date +'_'+seqname + '/' + imgnum + '_cam.txt', 'w')\n","                        # f.write(calib_representation)\n","                        f.close()\n","                        ct+=1\n","\n","                        except:\n","                            print(\"Error with reforming image!!!\")\n","                            print(img)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KLoZ0PYtH0iA","colab_type":"text"},"source":["Cropping script: Actual"]},{"cell_type":"code","metadata":{"id":"OAxCHPxuHyEC","colab_type":"code","outputId":"596f2176-1822-43f9-c24f-c12e5be7ee04","executionInfo":{"status":"ok","timestamp":1579992277618,"user_tz":480,"elapsed":1526988,"user":{"displayName":"ALEXANDER SAFONOV","photoUrl":"","userId":"06108573154481941124"}},"colab":{"base_uri":"https://localhost:8080/","height":238}},"source":["import cv2\n","import shutil\n","## [1]: Create masks\n","# iterate through batches, for each video, if there are no masks, create masks from det file by create mask from bounding boxes and resizing\n","## training \n","num1 = (126, 46)\n","\n","root = '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents'\n","# path\n","train_path = root + '/dataset/features/training/' \n","test_path = root +  '/dataset/features/testing/' \n","\n","mode1 = ['training' ,'testing' ]\n","path1 = [train_path, test_path]\n","\n","\n","path_odom = '/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/google-research/depth_from_video_in_the_wild/odometry_trajectory_outputs/'\n","path_depth = '/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/depth_maps/distance_maps/'\n","\n","# path to optimal crops\n","optimal_crop_path = '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/preprocessed_features/optimal_crops_SORT_det/' # shows the crops done for each image\n","\n","#dest_root_path = '/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/DenseDepth/google_distance_code/google_dist_code_1/google-research/depth_from_video_in_the_wild/data_example_1'\n","dest_root_path = '/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/'\n","## create numpy save file\n","for k in range(1,2):\n","  num = num1[k]\n","  mode = mode1[k]\n","  path = path1[k]\n","\n","  INPUT_DIR = '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/'+mode+'/'\n","  OUTPUT_DIR = '/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/'+mode+'/'\n","  if not OUTPUT_DIR.endswith('/'):\n","      OUTPUT_DIR = OUTPUT_DIR + '/'\n","\n","  for num_batch in range(1,num+1):\n","      if num_batch % 25 == 0:\n","        print('Batch:  ' + str(num_batch))\n","      #print num_batch %25\n","\n","      file_name = '%03d' %num_batch\n","      batch_data = np.load(path+'batch_'+file_name+'.npz', allow_pickle = True)\n","      optimal_crop = np.load(optimal_crop_path+mode+'/'+'batch_'+file_name+'.npz')\n","      # batch_xs = batch_data['data']\n","      batch_ys = batch_data['labels']\n","      batch_ID = batch_data['ID']\n","      batch_det = batch_data['det']\n","      batch_optimal_crop = optimal_crop['new_det']\n","      frame_paths, frame_labels = retrieve_dir1(batch_ys, batch_ID, mode, num)\n","      odom_paths = retrieve_dir_custom(path_odom, batch_data, mode, mode1[k], split_type=1)\n","      depth_paths = retrieve_dir_custom(path_depth, batch_data, mode, mode1[k])\n","\n","\n","      # print(frame_paths)\n","      for vids in range(10):\n","        dest_path=dest_root_path+mode+'/'+frame_labels[vids]+'_'+frame_paths[vids]\n","        cur_file = dest_path.split('/')[-2]\n","        img_list = os.listdir(frame_paths[vids])\n","        img_list = sort_dir(img_list)\n","        output_path1 = OUTPUT_DIR+frame_labels[vids]+'_'+cur_file\n","        \n","        files = glob.glob(output_path1 + '/*.png')\n","        files = sorted([file for file in files if not 'disp' in file and not 'flip' in file and not 'seg' in file])\n","\n","        # files = sorted(files)\n","        sample_img = cv2.imread(glob.glob(frame_paths[vids]+ '/*.jpg')[0])\n","        if sample_img.shape[0] != 720 or sample_img.shape[1] < 1000:\n","          if os.path.exists(output_path1):\n","            shutil.rmtree(output_path1)\n","\n","        if len(files) != 98:\n","          if os.path.exists(output_path1):\n","            shutil.rmtree(output_path1)\n","            print('Removing!')\n","            print(output_path1)\n","        opt_crop = np.max(np.max(batch_optimal_crop[vids,:,:,-2]))\n","        # check length of directory\n","\n","        if not os.path.exists(output_path1):\n","          # delete corresponding odometry file\n","          if os.path.exists(odom_paths[vids]):\n","            os.remove(odom_paths[vids])\n","            print('Odometry file removed!')\n","          #### Remove depth maps\n","          if os.path.exists(depth_paths[vids]):\n","            os.remove(depth_paths[vids])\n","            print('Depth file removed!')\n","\n","          os.mkdir(output_path1)\n","          print('Making_directory: '+output_path1)  \n","          ct = 1\n","          files = sort_dir(img_list)\n","\n","          for i in range(SEQ_LENGTH, len(files)+1, STEPSIZE):\n","                imgnum = str(ct).zfill(10)\n","                if os.path.exists(output_path1+'/'  + imgnum + '.png'):\n","                    ct+=1\n","                    continue\n","                big_img = np.zeros(shape=(HEIGHT, WIDTH*SEQ_LENGTH, 3))\n","                wct = 0\n","\n","                for j in range(i-SEQ_LENGTH, i):  # Collect frames for this sample.\n","                    img = cv2.imread(frame_paths[vids] +'/'+files[j])\n","                    \n","                    # try:\n","                    ORIGINAL_HEIGHT, ORIGINAL_WIDTH, _ = img.shape\n","\n","                    cropped = selective_crop(img, opt_crop)\n"," \n","                    if (np.abs(cropped.shape[0]-128)>30) and (np.abs(cropped.shape[1]-416)>30):\n","                        print('Size Reshaped: ')\n","                        x_1 = np.zeros((720,1280, 3))\n","                        x_1[0:x.shape[0], 0:x.shape[1], :] = x  \n","                        cropped = selective_crop(img, opt_crop)\n","\n","                    zoom_x = WIDTH/ORIGINAL_WIDTH\n","                    zoom_y = HEIGHT/ORIGINAL_HEIGHT\n","\n","                    img = cv2.resize(cropped, (WIDTH, HEIGHT))\n","                    big_img[:,wct*WIDTH:(wct+1)*WIDTH] = img\n","                    wct+=1\n","\n","                    ## Change writing path !!!!!!!!!!!!!!!!!!!!!\n","                    cv2.imwrite(output_path1 + '/' + imgnum + '.png', big_img)\n","                    # print(\"Writing: \" + output_path1 + '/' + imgnum + '.png')\n","                    f = open(output_path1 + '/' + imgnum + '_cam.txt', 'w')\n","\n","                    # f.write(calib_representation)\n","                    f.close()\n","                    ct+=1\n","\n","                    # except:\n","                    #     print(\"Error with reforming image!!!\")\n","                    #     print(img)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Batch:  25\n","Making_directory: /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/testing/negative_001010\n","Making_directory: /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/testing/negative_001012\n","Making_directory: /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/testing/negative_001011\n","Making_directory: /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/testing/negative_001118\n","Making_directory: /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/testing/positive_000579\n","Making_directory: /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/testing/negative_001117\n","Making_directory: /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/testing/positive_000606\n","Making_directory: /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/testing/positive_000595\n","Making_directory: /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/testing/negative_001119\n","Making_directory: /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/testing/negative_001102\n","Making_directory: /content/gdrive/My Drive/Accident_Anticipation/depth_estimation/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/testing/positive_000558\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"P13nDryrxKLJ","colab_type":"text"},"source":["# For loop to make masks"]},{"cell_type":"code","metadata":{"id":"ffVHnpj7FCq8","colab_type":"code","colab":{}},"source":["## [1]: Create masks\n","# iterate through batches, for each video, if there are no masks, create masks from det file by create mask from bounding boxes and resizing\n","## training \n","num1 = (126, 46)\n","\n","mode1 = ['training' ,'testing' ]\n","path1 = [train_path, test_path]\n","\n","#dest_root_path = '/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/DenseDepth/google_distance_code/google_dist_code_1/google-research/depth_from_video_in_the_wild/data_example_1'\n","dest_root_path = '/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/DenseDepth/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs/'\n","## create numpy save file\n","for k in range(2):\n","  num = num1[k]\n","  mode = mode1[k]\n","  path = path1[k]\n","\n","  for num_batch in range(1,num+1):\n","      file_name = '%03d' %num_batch\n","      batch_data = np.load(path+'batch_'+file_name+'.npz', allow_pickle = True)\n","      batch_xs = batch_data['data']\n","      batch_ys = batch_data['labels']\n","      batch_ID = batch_data['ID']\n","      batch_det = batch_data['det']\n","      frame_paths, frame_labels = retrieve_dir1(batch_ys, batch_ID, mode, num)\n","\n","      for vids in range(10):\n","        dest_path=dest_root_path+mode+'/'+frame_labels[vids]+'_'+frame_paths[vids]\n","        \n","        dest_path_subdir_list = os.listdir(dest_path)\n","        if ('0000000001_fseg.png' in dest_path_subdir_list):\n","          pass\n","        else:\n","          print(dest_path)\n","          ## add if statement to get rid of folders that already have segmentation masks\n","\n","          for mask_frames in range(97):\n","            cur_bound_box = batch_det[vids,mask_frames,:,0:4]\n","            cur_mask = np.zeros((720,1280))\n","\n","            for k in range(cur_bound_box.shape[0]):\n","              if np.sum(cur_bound_box[k,:]) != 0:\n","                bb = cur_bound_box[k,:].astype(int)\n","                cur_mask[bb[1]:bb[3], bb[0]:bb[2]] = 1\n","            ## Add boolean values of mask\n","            ############\n","            cropped = crop(cur_mask)\n","            ############\n","\n","            if (np.abs(cropped.shape[0]-128)>30) and (np.abs(cropped.shape[1]-416)>30):\n","              x_1 = np.zeros((720,1280))\n","              x_1[0:cur_mask.shape[0], 0:cur_mask.shape[1]] = cur_mask  \n","              ############\n","              cropped = crop(x_1)\n","              ############\n","\n","            cropped = cv2.resize(cropped, (416,128))\n","\n","            mask_file_name = '%010d' %(mask_frames*3+1)+'_fseg.png'\n","\n","            mask_path = dest_path+'/'+mask_file_name\n","            cropped = cropped.astype('uint8')\n","\n","            cv2.imwrite(mask_path, cropped * 255)\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xgtnpvk59hmZ","colab_type":"code","colab":{}},"source":["a2 = ['positive', 'negative']\n","mode = 'training'\n","# for ak in range(len(a1)):\n","#   mode = a1[ak]\n","for ak2 in range(len(a2)):\n","  mode2 = a2[ak2]\n","  dir_list = np.sort(os.listdir(source_path+'/'+mode+'/'+mode2))\n","  for ak3 in range(len(dir_list)):\n","    cur_src_path = source_path+'/'+mode+'/'+mode2+'/'+dir_list[ak3]\n","    cur_dest_path = destination_path +'/'+mode+'/'+mode2+'_'+dir_list[ak3]\n","\n","    dest = shutil.copytree(cur_src_path, cur_dest_path)\n","\n","    print(cur_src_path)\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1qwjbuVT8eE_","colab_type":"code","colab":{}},"source":["!pwd"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LN-3Ef7o7ypk","colab_type":"code","colab":{}},"source":["print(os.listdir('./accident_data/reformatting_imgs/final_outputs'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"D5MKpFEwcvet","colab_type":"code","colab":{}},"source":["SEQ_LENGTH = 3\n","WIDTH = 416\n","HEIGHT = 128\n","STEPSIZE = 1\n","INPUT_DIR = './new_imgs/testing/'\n","OUTPUT_DIR = './depth_estimation/DenseDepth/google_distance_code/accident_data/reformatting_imgs/final_outputs/testing/'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NXqK2V8tcyTR","colab_type":"code","colab":{}},"source":["def get_line(file, start):\n","    file = open(file, 'r')\n","    lines = file.readlines()\n","    lines = [line.rstrip() for line in lines]\n","    ret = None\n","    for line in lines:\n","        nline = line.split(': ')\n","        if nline[0]==start:\n","            ret = nline[1].split(' ')\n","            ret = np.array([float(r) for r in ret], dtype=float)\n","            ret = ret.reshape((3,4))[0:3, 0:3]\n","            break\n","    file.close()\n","    return ret\n","\n","def crop(img):\n","    # Perform center cropping, preserving 50% vertically.\n","    middle_perc = 0.50\n","    left = 1-middle_perc\n","    half = left/2\n","    a = img[int(img.shape[0]*(half)):int(img.shape[0]*(1-half)), :]\n","\n","    # Resize to match target height while preserving aspect ratio.\n","    wdt = int((128*a.shape[1]/a.shape[0]))\n","    x_scaling = float(wdt)/a.shape[1]\n","    y_scaling = 128.0/a.shape[0]\n","    b = cv2.resize(a, (wdt, 128))\n","\n","    # Perform center cropping horizontally.\n","    remain = b.shape[1] - 416\n","    # cx /= (b.shape[1]/416)\n","    c = b[:, int(remain/2):b.shape[1]-int(remain/2)]\n","\n","    return c\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eHnsiZpAMccS","colab_type":"text"},"source":["Cropping Images"]},{"cell_type":"code","metadata":{"id":"dVDx-n6vdd7F","colab_type":"code","colab":{}},"source":["# def run_all():\n","#   ct = 0\n","#   OUTPUT_DIR = './depth_estimation/DenseDepth/google_distance_code/accident_data/reformatting_imgs/final_outputs/testing/'\n","#   if not OUTPUT_DIR.endswith('/'):\n","#       OUTPUT_DIR = OUTPUT_DIR + '/'\n","\n","#   ## d is positive or negative\n","#   for d in glob.glob(INPUT_DIR + '/*/'):\n","#       date = d.split('/')[-2]\n","#       # file_calibration = d + 'calib_cam_to_cam.txt'\n","#       # calib_raw = [get_line(file_calibration, 'P_rect_02'), get_line(file_calibration, 'P_rect_03')]\n","\n","#       ## d2 is the actual folder creating the file sequence\n","#       for d2 in glob.glob(d + '*/'):\n","#           seqname = d2.split('/')[-2]\n","#           print('Processing sequence', seqname)\n","#           # for subfolder in ['image_02/data', 'image_03/data']:\n","#           ct = 1\n","#           # image_0 is a subfolder of the sequence\n","#           # addition = '/image_0'\n","\n","#           print(OUTPUT_DIR+'/'+date+'/'+seqname)\n","\n","#           if not os.path.exists(OUTPUT_DIR +'/'+date+'/'+seqname):\n","\n","#               break\n","#               os.mkdir(OUTPUT_DIR +'/'+date+'/'+ seqname)\n","#               print('made dir ' + '/'+date+'/'+ seqname)\n","#               # calib_camera = calib_raw[0] if subfolder=='image_02/data' else calib_raw[1]\n","#               folder = d2 #+addition\n","#               print(folder)\n","#               files = glob.glob(folder + '/*.png')\n","#               files = [file for file in files if not 'disp' in file and not 'flip' in file and not 'seg' in file]\n","#               files = sorted(files)\n","#               for i in range(SEQ_LENGTH, len(files)+1, STEPSIZE):\n","#                   imgnum = str(ct).zfill(10)\n","#                   if os.path.exists(OUTPUT_DIR + seqname + '/' + imgnum + '.png'):\n","#                       ct+=1\n","#                       continue\n","#                   big_img = np.zeros(shape=(HEIGHT, WIDTH*SEQ_LENGTH, 3))\n","#                   wct = 0\n","\n","#                   for j in range(i-SEQ_LENGTH, i):  # Collect frames for this sample.\n","#                       img = cv2.imread(files[j])\n","                      \n","#                       try:\n","#                           ORIGINAL_HEIGHT, ORIGINAL_WIDTH, _ = img.shape\n","\n","#                           cropped = crop(img)\n","#                           if (np.abs(cropped.shape[0]-128)>30) and (np.abs(cropped.shape[1]-416)>30):\n","#                               x_1 = np.zeros((720,1280, 3))\n","#                               x_1[0:x.shape[0], 0:x.shape[1], :] = x  \n","#                               cropped = crop(x_1)\n","\n","#                           zoom_x = WIDTH/ORIGINAL_WIDTH\n","#                           zoom_y = HEIGHT/ORIGINAL_HEIGHT\n","\n","#                           img = cv2.resize(cropped, (WIDTH, HEIGHT))\n","#                           big_img[:,wct*WIDTH:(wct+1)*WIDTH] = img\n","#                           wct+=1\n","#                           cv2.imwrite(OUTPUT_DIR+date +'/'+ seqname + '/' + imgnum + '.png', big_img)\n","#                           f = open(OUTPUT_DIR +date +'/'+seqname + '/' + imgnum + '_cam.txt', 'w')\n","#                           # f.write(calib_representation)\n","#                           f.close()\n","#                           ct+=1\n","\n","#                       except:\n","#                           print(\"Error with reforming image!!!\")\n","#                           print(img)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"itvm0QUUdBm-","colab_type":"code","colab":{}},"source":["run_all()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2SDTD7Chhdg5","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QeVfKLVztTZ0","colab_type":"code","colab":{}},"source":["# ## Change function to retrieve frame directories\n","# def retrieve_dir1(labels,ID, str_mode, n_batches):\n","#     frame_paths = list()\n","#     frame_labels = list()\n","#     frame_path1 = '/content/gdrive/My Drive/Accident_Anticipation/Anticipating-Accidents/dataset/videos/frames/'\n","#     # list of strings, gives names of videos\n","\n","#     for ak in range(len(labels)):\n","#         if labels[ak,1] == 1: # conditional for positive example\n","#             str2 = 'positive'\n","#             file_name = ID[ak].decode('utf-8')\n","#         else:\n","#             str2 = 'negative'\n","#             if str_mode == 'training':\n","#               neg_vid = range(1,1+len(os.listdir(frame_path1 +str_mode+'/'+str2+'/')))\n","#               cf = int(ID[ak].decode('utf-8'))-1\n","#             else:\n","#               neg_vid = range(830,1+1130)\n","#               cf = int(ID[ak].decode('utf-8'))-830\n","#             cf = np.roll(neg_vid,-2)[cf]\n","#             file_name = '%06d' %cf # negative videos shifted by 2\n","\n","#         corr = file_name\n","\n","#         if labels[ak,1] == 1: #positive\n","#           if (str_mode == 'testing'):\n","#               if (file_name == '000556'):\n","#                   corr = '000506'\n","#               elif (file_name == '000606'):\n","#                   corr = '000556'     \n","#               #elif (file_name == '000506'):\n","#               #    ignore_boxes_flags[ak] = 1           \n","#           else: #training\n","#               if (file_name == '000101'):\n","#                   corr = '000051'\n","#               elif (file_name == '000251'):\n","#                   corr = '000201'\n","#               elif (file_name == '000301'):\n","#                   corr = '000251'\n","#               elif (file_name == '000351'):\n","#                   corr = '000301'\n","#               elif (file_name == '000401'):\n","#                   corr = '000351'\n","#               #elif ((file_name == '000051') or file_name == '000201' ):\n","#               #    ignore_boxes_flags[ak] = 1\n","                              \n","#         else: #negative\n","#             if (str_mode == 'testing'): \n","#                 if (file_name == '001030'):\n","#                     corr = '000930'\n","#                 elif (file_name == '001130'):\n","#                     corr = '001030'\n","#                 #elif (file_name == '000930'):\n","#                 #    ignore_boxes_flags[ak] = 1\n","#             else: #training\n","#                 if (file_name == '000201'):\n","#                     corr = '000101'\n","#                 elif (file_name == '000301'):\n","#                     corr = '000201'\n","#                 elif (file_name == '000401'):\n","#                     corr = '000301'\n","#                 elif (file_name == '000501'):\n","#                     corr = '000401'\n","#                 elif (file_name == '000601'):\n","#                     corr = '000501'\n","#                 elif (file_name == '000701'):\n","#                     corr = '000601'\n","#                 elif (file_name == '000801'):\n","#                     corr = '000701'\n","#                 elif (file_name == '000001'):\n","#                     corr = '000801'\n","#                 elif (file_name == '000101'):\n","#                     corr = '000001'            \n","#         # file_name = corr\n","#         frames_path = frame_path1 +str_mode+'/'+str2+'/'+file_name+'/'\n","#         frame_paths.append(frames_path)\n","#         frame_labels.append(str2)\n","#     return frame_paths, frame_labels\n","\n","# def crop(img):\n","#     # Perform center cropping, preserving 50% vertically.\n","#     middle_perc = 0.50\n","#     left = 1-middle_perc\n","#     half = left/2\n","#     a = img[int(img.shape[0]*(half)):int(img.shape[0]*(1-half)), :]\n","\n","#     # Resize to match target height while preserving aspect ratio.\n","#     wdt = int((128*a.shape[1]/a.shape[0]))\n","#     x_scaling = float(wdt)/a.shape[1]\n","#     y_scaling = 128.0/a.shape[0]\n","#     b = cv2.resize(a, (wdt, 128))\n","\n","#     # Perform center cropping horizontally.\n","#     remain = b.shape[1] - 416\n","#     # cx /= (b.shape[1]/416)\n","#     c = b[:, int(remain/2):b.shape[1]-int(remain/2)]\n","#     return c\n","\n","# def top_crop(img):\n","#     # Perform center cropping, preserving 50% vertically.\n","#     middle_perc = 0.50\n","#     left = 1-middle_perc\n","#     half = left/2\n","#     a = img[int(0):int(img.shape[0]*(left)), :]\n","\n","#     # Resize to match target height while preserving aspect ratio.\n","#     wdt = int((128*a.shape[1]/a.shape[0]))\n","#     x_scaling = float(wdt)/a.shape[1]\n","#     y_scaling = 128.0/a.shape[0]\n","#     b = cv2.resize(a, (wdt, 128))\n","\n","#     # Perform center cropping horizontally.\n","#     remain = b.shape[1] - 416\n","#     # cx /= (b.shape[1]/416)\n","#     c = b[:, int(remain/2):b.shape[1]-int(remain/2)]\n","#     return c\n","\n","# def bottom_crop(img):\n","#     # Perform center cropping, preserving 50% vertically.\n","#     middle_perc = 0.50\n","#     left = 1-middle_perc\n","#     half = left/2\n","#     a = img[int(img.shape[0]*(left)):-1, :]\n","\n","#     # Resize to match target height while preserving aspect ratio.\n","#     wdt = int((128*a.shape[1]/a.shape[0]))\n","#     x_scaling = float(wdt)/a.shape[1]\n","#     y_scaling = 128.0/a.shape[0]\n","#     b = cv2.resize(a, (wdt, 128))\n","\n","#     # Perform center cropping horizontally.\n","#     remain = b.shape[1] - 416\n","#     # cx /= (b.shape[1]/416)\n","#     c = b[:, int(remain/2):b.shape[1]-int(remain/2)]\n","#     return c\n","\n","# def selective_crop(img, crop_type):\n","#   if crop_type == 1:\n","#     c = top_crop(img)\n","#   elif crop_type == 3:\n","#     c = bottom_crop(img)\n","#   else:\n","#     c = crop(img)\n","#   return c\n","\n","# def obtain_keys(lis):\n","#     key_ls = list()\n","#     for k in lis:\n","#         integer = re.split('([0-9]+)', k)[1]\n","#         key_ls.append(int(integer))\n","#     return(key_ls)\n","  \n","# def obtain_keys1(lis):\n","#     key_ls = list()\n","#     for k in lis:\n","#         integer = re.split('([0-9]+)', k)[3]\n","#         key_ls.append(int(integer))\n","#     return(key_ls)\n","  \n","# def h(seq):\n","#     return sorted(range(len(seq)), key=seq.__getitem__)\n","  \n","# def sort_dir(lis):\n","#     key_ls = h(obtain_keys(lis))\n","#     return [lis[i] for i in key_ls]\n","\n","\n","# ## change up load_images to resize images and stack them\n","# def load_images(image_files):\n","#     from skimage.transform import resize\n","#     loaded_images = []\n","#     iter1 = 0\n","\n","#     for file in image_files:\n","#         img_1 = read_resize_img(file)\n","\n","#         # crop_middle = selective_cropping2(file)\n","\n","#         if iter1 == 0:\n","#           img_stack = np.expand_dims(img_1, axis = 0)\n","#         else:\n","#           img_stack = np.concatenate((img_stack,  np.expand_dims(img_1, axis = 0) ), axis = 0)\n","#         if file == image_files[-1]:\n","#           # read image 98\n","#           img_crop_2 = read_resize_img_crop(file,416,416*2)\n","#           img_stack = np.concatenate((img_stack,  np.expand_dims(img_crop_2, axis = 0) ), axis = 0)\n","#           # read image 99\n","#           img_crop_3 = read_resize_img_crop(file,416*2,416*3)\n","#           img_stack = np.concatenate((img_stack,  np.expand_dims(img_crop_3, axis = 0) ), axis = 0)\n","#         iter1+=1\n","\n","\n","#     return img_stack\n","\n","# def read_resize_img(img):\n","#   x = np.clip(np.asarray(Image.open( img ), dtype=float) / 255, 0, 1)\n","#   return x[0:128, 0:416,:]\n","\n","# def read_resize_img_crop(img,y1,y2):\n","#   x = np.clip(np.asarray(Image.open( img ), dtype=float) / 255, 0, 1)\n","#   return x[0:128, y1:y2,:]\n","\n","# def selective_cropping2(img):\n","#   x = np.clip(np.asarray(Image.open( img ), dtype=float) / 255, 0, 1)\n","#   cropped = np.expand_dims(crop(x), axis = 0)\n","#   cropped1 = None\n","#   cropped2 = None\n","#   if (np.abs(cropped.shape[1]-128)>30) and (np.abs(cropped.shape[2]-416)>30):\n","#     x_1 = np.zeros((720,1280, 3))\n","#     x_1[0:x.shape[0], 0:x.shape[1], :] = x  \n","#     cropped = np.expand_dims(crop(x_1), axis = 0)\n","#   else:\n","#     cropped1 = np.expand_dims(crop_upper(x), axis = 0)[:,:,0:-1,:]\n","#     cropped2 = np.expand_dims(crop_lower(x), axis = 0)[:,:,0:-1,:]\n","#   cropped = cropped[:,:,0:-1,:]\n","#   img_shape = x.shape\n","#   return cropped, cropped1, cropped2, img_shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"k20OicsWyRga","colab_type":"code","colab":{}},"source":["## [1]: Create masks\n","# iterate through batches, for each video, if there are no masks, create masks from det file by create mask from bounding boxes and resizing\n","## training \n","num1 = (126, 46)\n","\n","mode1 = ['training' ,'testing' ]\n","path1 = [train_path, test_path]\n","\n","#dest_root_path = '/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/DenseDepth/google_distance_code/google_dist_code_1/google-research/depth_from_video_in_the_wild/data_example_1'\n","dest_root_path = '/content/gdrive/My Drive/Accident_Anticipation/depth_estimation/DenseDepth/google_distance_code/accident_data/reformatting_imgs/reordered_final_outputs_2/'\n","## create numpy save file\n","for k in range(2):\n","  num = num1[k]\n","  mode = mode1[k]\n","  path = path1[k]\n","\n","  for num_batch in range(1,num+1):\n","      file_name = '%03d' %num_batch\n","      batch_data = np.load(path+'batch_'+file_name+'.npz', allow_pickle = True)\n","      optimal_crop = np.load(optimal_crop_path+mode+'/'+'batch_'+file_name+'.npz')\n","      # batch_xs = batch_data['data']\n","      batch_ys = batch_data['labels']\n","      batch_ID = batch_data['ID']\n","      batch_det = batch_data['det']\n","      batch_optimal_crop = optimal_crop['new_det']\n","      frame_paths, frame_labels = retrieve_dir1(batch_ys, batch_ID, mode, num)\n","      \n","      # print(frame_paths)\n","      for vids in range(10):\n","        dest_path=dest_root_path+mode+'/'+frame_labels[vids]+'_'+frame_paths[vids]\n","        cur_file = dest_path.split('/')[-2]\n","        img_list = os.listdir(frame_paths[vids])\n","        output_path1 = OUTPUT_DIR+mode+'/'+frame_labels[vids]+'_'+cur_file\n","        opt_crop = np.max(np.max(batch_optimal_crop[vids,:,:,-2]))\n","\n","        if not os.path.exists(output_path1):\n","        # if True:\n","            os.mkdir(output_path1)\n","            print('Making_directory: '+output_path1)\n","            ct = 1\n","            files = sort_dir(img_list)\n","\n","            for i in range(SEQ_LENGTH, len(files)+1, STEPSIZE):\n","                  imgnum = str(ct).zfill(10)\n","                  if os.path.exists(output_path1 + '/' + imgnum + '.png'):\n","                      ct+=1\n","                      continue\n","                  big_img = np.zeros(shape=(HEIGHT, WIDTH*SEQ_LENGTH, 3))\n","                  wct = 0\n","\n","                  for j in range(i-SEQ_LENGTH, i):  # Collect frames for this sample.\n","                      img = cv2.imread(frame_paths[vids] +'/'+files[j])\n","                      \n","                      # try:\n","                      ORIGINAL_HEIGHT, ORIGINAL_WIDTH, _ = img.shape\n","\n","                      cropped = selective_crop(img, opt_crop)\n","                      if (np.abs(cropped.shape[0]-128)>30) and (np.abs(cropped.shape[1]-416)>30):\n","                          x_1 = np.zeros((720,1280, 3))\n","                          x_1[0:x.shape[0], 0:x.shape[1], :] = x  \n","                          cropped = selective_crop(img, opt_crop)\n","\n","                      zoom_x = WIDTH/ORIGINAL_WIDTH\n","                      zoom_y = HEIGHT/ORIGINAL_HEIGHT\n","\n","                      img = cv2.resize(cropped, (WIDTH, HEIGHT))\n","                      big_img[:,wct*WIDTH:(wct+1)*WIDTH] = img\n","                      wct+=1\n","\n","                      ## Change writing path !!!!!!!!!!!!!!!!!!!!!\n","                      cv2.imwrite(output_path1 + '/' + imgnum + '.png', big_img)\n","                      # print(\"Writing: \" + output_path1 + '/' + imgnum + '.png')\n","                      f = open(output_path1 + '/' + imgnum + '_cam.txt', 'w')\n","\n","                      # f.write(calib_representation)\n","                      f.close()\n","                      ct+=1\n","\n","                      # except:\n","                      #     print(\"Error with reforming image!!!\")\n","                      #     print(img)"],"execution_count":0,"outputs":[]}]}